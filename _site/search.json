[
  {
    "objectID": "Workshop3_plot-types.html",
    "href": "Workshop3_plot-types.html",
    "title": "Exploring Plot Types",
    "section": "",
    "text": "In this section, you’ll learn how to make a variety of plots in R using ggplot2, including some that aren’t possible (or are painful!) in Excel. We’ll continue to use the delaney_processed.csv dataset to explore the distributions and relationships between molecular properties and solubility.\n\nHistograms\n\nA basic histogram\nA histogram shows the shape of a continuous variable, perfect for variables like solubility, molecular weight, polar surface area, etc.\nLet’s start by plotting a basic histogram:\n\n\n\n\n\n\n\n\nThe line:\ngeom_histogram(binwidth = 0.5, fill = \"steelblue\", colour = \"white\")\nadds a histogram layer to the ggplot. Each argument controls a different aspects of how the histogram looks:\n\ngeom_histogram(...) tells ggplot to araw a histogram of the variable mapped inside aes().\nbinwidth = 0.5 sets how wide each bar (“bin”) should be. A smaller binwidth produces more bars hence more detail but equally, more noise. A larger binwidth, on the other hand, is smoother but less detailed.\nfill = \"steelblue\" sets the inside colour of each bar. There are a LOT (!) of named colours in R (at last count, 655… you can see the whole list by typing colours() in the Console). The command fill also takes both rgb() and hex code inputs (if you’re not sure of the name!).\ncolour = \"white\" sets the outline colour of the bars.\n\nTry changing the colour of the bars to yellowgreen or orchid and see what happens.\n\n\nPlotting a histogram with a density curve\nYou may want to plot both the bars of a histogram and a smooth curve showing the distribution. Try the command below:\n\n\n\n\n\n\n\n\nThere are two key differences between the code here and that of earlier:\n\naes(y = after_stat(density)), which scales the histogram so that the total area under the curve is equal to 1 rather than the frequency count.\ngeom_density() adds the density curve on top.\n\n\n\nPlotting a histogram with a rug plot\nA rug is simply a tick mark (“rug”). A rug plot therefore shows tick marks for each individual datapoint along the axis. By defaut, the rug is plotted along the x-axis at the bottom of the plot. Try adding a call to geom_rug() to the end of the command below to add the rug!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nYou should add: + geom_rug() to the end of the command to add another layer, which, in this case is the rug.\n\n\n\n\n\n\n\nggplot(data, aes(x = `measured log solubility in mols per litre`)) + geom_histogram(binwidth = 0.5, fill = \"steelblue\", colour = \"white\") + geom_rug()\nggplot(data, aes(x = `measured log solubility in mols per litre`)) + geom_histogram(binwidth = 0.5, fill = \"steelblue\", colour = \"white\") + geom_rug()\n\n\n\n\n\n\n\n\n\nBoxplots\n\nA basic boxplot\nBoxplots are excellent for summarising distributions and spotting outliers. A default boxplot in R follows the standard Tukey format i.e. it shows the middle 50% of the data inside the box (from the 25th to 75th percentile), with a line marking the median. The “whiskers” extend to the largest and smallest values that aren’t extreme, and any points beyond them are outliers.\nLet’s try plotting a basic boxplot with the data:\n\n\n\n\n\n\n\n\nHere, all we’ve done is added a layer creating a boxplot using the command geom_boxplot().\nWe could take this a bit further and, by treating the number of H-bond donors as a categorical variable (since its discrete), we can use the boxplots to see if there are any trends relating the number of H-bond donors to the solubility.\n\n\n\n\n\n\n\n\nHere, the command factor() converts the numeric integers into categorical labels.\nWe can go even further and overlay the original datapoints - we’ll use the geom_jitter() command so that the datapoints are spread out a bit, to avoid overlapping! This is known as jittering.\nAdd the line:\ngeom_jitter(width = 0.2, alpha = 0.5)\nto the following:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nYou should add: + geom_jitter(width = 0.2, alpha = 0.5) to the end of the command to add another layer of jittered points.\n\n\n\n\n\n\n\nggplot(data, aes(x = factor(`Number of H-Bond Donors`), y = `measured log solubility in mols per litre`)) + geom_boxplot(fill = \"lightgreen\") + geom_jitter(width = 0.2, alpha = 0.5)\nggplot(data, aes(x = factor(`Number of H-Bond Donors`), y = `measured log solubility in mols per litre`)) + geom_boxplot(fill = \"lightgreen\") + geom_jitter(width = 0.2, alpha = 0.5)\n\n\n\n\n\n\nTry playing around with the width and alpha values to see what happens!\nIt should be noted that these types of overlays are extremely hard to do in Excel (without considerable coding etc.).\n\n\n\nViolin plots\nYou may not have heard of violin plots before but they are very exciting!! In brief, a violin plot shows the full distribution of a continuous variable by combining a boxplot with a mirrored density curve, so you can see where values are concentrated. The width of the “violin” at each point represents the density of observations, giving more detail than a standard boxplot.\nThis can be illustrated using the command below (don’t fret about the warning that will come up!):",
    "crumbs": [
      "Home",
      "Workshop 3",
      "Exploring Plot Types"
    ]
  },
  {
    "objectID": "Workshop3_ggplot.html",
    "href": "Workshop3_ggplot.html",
    "title": "Loading Data and Making Your First Plot",
    "section": "",
    "text": "Importing the dataset\nIn Worksheet 2, you learnt how to import CSV datasets using the readr package and its read_csv() command. In this section, we’ll apply the same skills to the Delaney solubility dataset (this is actually the original ‘esol’ dataset so you may recognise it!). You’ll perform the import both in WebR (within your browser) and in RStudio (on your computer). To get started, simply select one of the buttons below:\n\nWebRRStudio\n\n\nYou’ll be using the dataset “delaney-processed.csv”. As with Worksheet 2, this is a .csv file and therefore needs to be imported using the readr package. For simplicity, this has already been installed and loaded up for you. We can therefore simply read it into a dataframe, which we are going to call data. On WebR, the delaney-processed.csv file has been saved into a folder (weirdly also) called data, so we need to ensure that we call it from that folder:\n\n\n\n\n\n\n\n\n\n\nStep 1: Firstly, check that the packages that you will need today are installed. For this worksheet, you’ll need either: (i)tidyverse (which includes both readr and ggplot2) OR readr, and ggplot2.\nYou can either install packages in RStudio by selecting the ‘Tools’ tab, then ‘Install packages…’ (as per the video below), or simply type (in Console):\ninstall.packages(\"tidyverse\")\n(here, this would install the package tidyverse) remembering that you must always include inverted commas.\n\nStep 2: Open the packages, using the library command i.e.:\nlibrary(tidyverse)\nStep 3: Download the delaney-processed.csv file from Canvas: CH4004 Mathematics and R Computing (scroll all the way down to the Workshops section) and take note of where you have saved it.\nStep 4: In RStudio, change the working directory to the location in which the file is saved. You can do this by clicking on the ‘Session’ tab, then ‘Set Working Directory’ and finally ‘Choose Directory…’. Watch the video below for more guidance.\n\nStep 5: Now you can read it into a dataframe, in the same way as for WebR i.e.:\ndata &lt;- read_csv(\"delaney-processed.csv\")\nJust remember that you don’t need a link to a ‘data’ folder as the csv file is stored in your working directory.\n\n\n\nFrom now on, you should just be able to copy and paste any commands straight into RStudio.\n\n\nCreating a basic ggplot\nHave a good look at the data in the .csv file… there is a lot of information in it, including chemical compound names, molecular weights and their solubilities.\nWe’ll begin by plotting molecular weight against measured log solubility. This is a useful start as molecular weight is one of the simplest molecular descriptors and might (or might not!) correlate with solubility.\nSolubility (i.e. the number of moles of a compound that dissolves in one litre of water) is given here as a log value since many of the compounds are only sparingly soluble!! So… while methanol is extremely soluble, compounds such as tetradecane are practically insoluble with a solubility value of &lt; 1 \\(\\times\\) 10\\(^{-8}\\) mol/L.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlike standard plots, a ggplot is a way of creating plots in R using a layered grammar of graphics, where you start with a dataset and then add layers to define what’s displayed. Each layer can represent points, lines or other visual elements, and you can customise axes, colours and themes to clearly communicate your data.\nHere, the command ggplot(data, aes(...)) starts a new ggplot and tells R to use your dataset called data.\nInside the aes() (“aesthetics”) function, you specify which variables to plot:\n\nx = Molecular Weight places the compounds’ molecular weight (where the column is called Molecular Weight) on the horizontal axis.\ny = measured log solubility in mols per litre places the measured log solubility on the vertical axis.\n\nThe plus symbol, + is used in ggplot to “add layers”. Each new layer modifies or enhances the plot.\ngeom_point() adds a layer of points to create a scatter plot, which is commonly used to examine relationships between two continuous variables. In this case, it allows us to explore whether molecular weight appears to influence solubility. From the graph that you’ve just made, we can clearly see that it does!\n\n\nExploring your data\nYou’ve already made a basic scatter plot of molecular weight vs. measured solubility. Now it’s time to experiment with mapping other variables to visual features.\nLet’s try adding extra features to this plot. The scatter points can (excitingly!) be mapped to other properties - so, as an example, the size of the points can be related to e.g. the number of hydrogen bond donors of the compound. The act of connecting a data variable to a visual property in this way is called aesthetic mapping.\nAt this point, it will be worthwhile having a look at the data to check what the names of the columns first! The command glimpse() is perfect for this i.e..\n\n\n\n\n\n\n\n\nIn order to map the size of the points to a variable, the command size needs to be included within the aes brackets. In the exercise below, replace the ... with the name of the column of data that represents the number of H bond donors in each compound. Remember to use backticks ` around your column name.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nThe relevant column is called Number of H-Bond Donors.\n\n\n\n\n\n\n\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`, size = `Number of H-Bond Donors`)) + geom_point()\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`, size = `Number of H-Bond Donors`)) + geom_point()\n\n\n\n\n\n\nClearly there is some dependence of solubility on the number of hydrogen bond donors in a compound. We can try visualising this by colour instead, to see if it’s more clear… as before, replace the ... in the box below with the relevant name of the column and see what happens:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nThe relevant column is called Number of H-Bond Donors. Remember to include backticks around the name.\n\n\n\n\n\n\n\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`, colour = `Number of H-Bond Donors`)) + geom_point()\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`, colour = `Number of H-Bond Donors`)) + geom_point()\n\n\n\n\n\n\nThe ability to colour map (using continuous colour scales) is not possible in Excel. In fact, in R you can also do many other fantastic graphing feats that aren’t possible in Excel.\nSome other properties of the scatter points that you might want to control are:\n\nShape\nFill\nTransparency (called ‘alpha’)\nLine type (this is for line plots rather than scatter plots!)\n\nIn the command line above, try replacing colour with alpha and see what happens!!",
    "crumbs": [
      "Home",
      "Workshop 3",
      "Loading Data and Making Your First Plot"
    ]
  },
  {
    "objectID": "Workshop2.html#welcome-to-workshop-2-cleaning-and-wrangling-your-chemistry-data",
    "href": "Workshop2.html#welcome-to-workshop-2-cleaning-and-wrangling-your-chemistry-data",
    "title": "Workshop 2",
    "section": "Welcome to Workshop 2: Cleaning and Wrangling Your Chemistry Data",
    "text": "Welcome to Workshop 2: Cleaning and Wrangling Your Chemistry Data\nIn this workshop, you will learn how to:\n\nLoad a chemistry dataset into R\nInspect the data to identify common issues\nPrepare for cleaning and wrangling tasks\n\n\nWorking with R Studio\nPlease load up R Studio, and once you’ve tested each the run code chunks in this browser version, try copying them over to R Studio and running them in that environment - I recommend that you do this as you go through! It’s very important that you get used to working in R Studio - so please do practice.\n\n\nSaving work\nFor the browser version (in Edge), you can click on the three dots in the top right hand corner, then select ‘print’ and then ‘print to pdf’.\n\n\nDatasets used in this worksheet\nWe will be working with two datasets:\n\nThe ESOL dataset, which contains aqueous solubility data for chemical compounds. This dataset has some intentional data issues for you to spot and fix.\nThe Lipophilicity dataset, which contains experimental logD values for small molecules, where the term lipophilicity represents a measure of how well a substance dissolves in fats, oils and lipids vs water!\n\n\n\nHow to use Code Chunks in this Worksheet?\nIn this tutorial, you’ll see two types of code chunks (I’m calling them ‘type 1’ and ‘type 2’ just for clarity for you, but in reality, they’re very similar:\n\nRun Code type 1 chunks: These are for trying things out — just click Run Code to see what happens!\nRun Code type 2 chunks: These ask you to complete a task. Once you’re happy with your answer, click Run Code to check your work… you’ll get feedback right away.\n\nSome Run Code type 2 exercises also come with Hint buttons (and possibly even a Show Solution button)to help you if you get stuck. Give it a try, there’s no penalty for exploring or making mistakes!\n\nExample 1: “Run Code” type 1 Chunk\nThis is a Run Code chunk: there’s nothing to submit, you’re just playing with code!\nTry running the code below to make R say hello:\n\n\n\n\n\n\n\n\n\n\n\nExample 2: “Run Code” Chunk type 2 (for graded feedback)\nThis is also a Run Code chunk. But… this time, after you’ve typed your answer and clicked Run Code, you’ll get graded feedback that will tell you if you’re correct and may even give you a hint about how to improve your answer!\nTalking of hints… you’ll see that, in this example, that there is also a button called Show Hint. Try clicking it and see what happens!\nIn this example, we’ll use nchar() to count the number of letters in the word \"banana\" and assign it to a variable called banana_length. Simply fill in the blank!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nRemember to keep the name of the word to be counted in inverted commas ” “.\n\n\n\n\n\n\n\nbanana_length &lt;- nchar(\"banana\")\nbanana_length &lt;- nchar(\"banana\")\n\n\n\n\n\n\n\n\n\nData Source Acknowledgement\nThe ESOL and Lipophilicity datasets used in this workshop are from MoleculeNet,\na benchmarking platform for molecular machine learning datasets.\nPlease refer to Wu et al., MoleculeNet: a benchmark for molecular machine learning, Chemical Science, 2018, 9, 513-530 for details.\nWe thank the authors and contributors for making these datasets publicly available.",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#understanding-r-packages",
    "href": "Workshop2.html#understanding-r-packages",
    "title": "Workshop 2",
    "section": "Understanding R packages",
    "text": "Understanding R packages\nIf you remember from last week, packages in R are like plug-ins or apps for R. They add extra tools and features that don’t come built-in, so you can do more things easily, such as reading data files or cleaning your data.\nIn this case, as we’ll be importing and manipulating datasets today, we’ll use the readr package to import .csv files and dplyr for data manipulation.\n\nHow package installation works\nWhen working in R (e.g. R Studio), you will need to install packages using the install.packages() command. For example:\ninstall.packages(\"readr\")\ninstall.packages(\"dplyr\")\nPlease note that for the browser version these have already been installed automatically for you but you will have to install them in R Studio - simply copy and paste the code in!\nIn R Studio, you can find out which packages have been installed by looking at the ‘Packages’ tab in the bottom right pane to spot them!\n\n\n\n\n\n\nNote\n\n\n\nImportant notes about installing packages:\nPackage names must be in quotation marks: install.packages(\"dplyr\"). Without quotes, as shown in the example here, you’ll get an error: install.packages(dplyr).\nYou only need to install a package once on your computer (assuming that this is not using the KU environment, which wipes this!). The setup script already checked for you and only installed packages you didn’t already have.\n\n\n\n\nExercise: Loading packages\nAfter packages are installed, you need to load them to use their functions. This is done with the library() function. Slightly differently from install.packages, you don’t have to have inverted commas around the name though (it doesn’t matter whether you have them or not). For example, if you wanted to load the ‘beepr’ package (having installed it first!), you’d type:\nlibrary(bleepr)\nIn case, by the way, you’re wondering what the bleepr package is, it’s as the name suggests… a package that enables you to get an audible alert whenever your code finishes.\nAnyway, back to the task at hand! Think of the difference between using install.packages and library like downloading an app from an app Store vs opening an app. You only need to download an app once on your device (or in your R environment). However, even if the app is installed, you can’t use it until you open it. And… every time you restart your computer or your phone (or R session), you’ll need to open the app again.\nTry loading both readr and dplyr in the box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nUse the library() function to load packages! Package names do NOT need quotes in library. For the package readr this would look like:\nlibrary(readr)\nNow you do the same for dplyr!\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 2\n\n\n\n\n\nUse the library() function to load packages. Remember, package names do NOT need quotes in library().\nlibrary(readr)\nlibrary(dplyr)\n\n\n\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(dplyr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: Again, just to reiterate, unlike installation (i.e. using install.packages), you need to load packages with library() every time you start a new R session!\n\n\nWhy Cleaning Your Data Matters in Chemistry\nIn pharmaceutical and chemical research, your data is only as good as its quality.\nWhether you’re working with:\n\nExperimental data (e.g. solubility measurements from the lab), or\n\nLiterature-mined data (e.g. scraped or compiled from journal articles or public databases),\n\n…there are often errors, inconsistencies, or missing values that need fixing before any meaningful analysis.\n\n\nCommon data problems in chemistry:\n\nMissing or incomplete values (e.g. no logS reported for some compounds)\n\nUnits or scales that don’t match (e.g. logP vs. logD, or µg/mL vs. mol/L)\n\nInconsistent naming of chemical compounds\n\nDuplicate entries in literature-mined datasets\n\nImplausible values (e.g. negative molecular weights!)\n\n\nWhy it matters:\nIf we skip the cleaning step, we risk drawing wrong conclusions — or feeding errors into models or visualisations. It’s like trying to bake a cake with the wrong ingredients.",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#importing-the-esol-dataset",
    "href": "Workshop2.html#importing-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Importing the ESOL Dataset",
    "text": "Importing the ESOL Dataset\nNow let’s load a sample dataset: ESOL, a solubility dataset containing chemical compounds with their predicted aqueous solubility (logS), molecular weight (MolWt), and other properties.\n\nWe’ve introduced a few intentional issues to simulate what real chemical datasets often look like!\n\nYou can access the file esol_messy.csv from the data folder associated with this tutorial.\n\n\nExercise: Import the ESOL dataset\nYou’re going to import the file esol_messy.csv into R using read_csv() from the readr package.\n\n\n\n\n\n\nTip\n\n\n\nImportant reminder:\nWhen you use read_csv(), it reads the data — but it doesn’t automatically store it anywhere.\nYou need to assign the result to a data frame (just like we did last week) using the &lt;- operator.\n\n\nFor this exercise, please assign your data to an object called esol_data. The file itself is called esol_messy.csv and it’s in a folder called data on the browser. You will therefore have to group these two together as: data/esol_messy.csv.\nOkay… your go! Please have a go at importing your data using read_csv():\n\n\n\n\n\n\n\n\nHopefully that’s worked!! Don’t worry if your code didn’t quite work though… I’ve made sure the dataset is available behind the scenes so you can still follow along with the next steps. But… just in case you had any issues, and if you want to keep on, feel free to go back and try again!\nWhen doing this in R Studio, you will need to download the files from Canvas, save them and ensure that you have included its full address, rather than just ‘data/’.\nTip: You can use the print() command with the name of your variable (here: esol_data) e.g. print(VARIABLE) to display the entire dataset (or as much of it as fits in your window). This can help you get a quick overview of the data contents. Why don’t you try that in the box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nUse the print() function with the name of the function (here: esol_data)\nprint(esol_data)\n\n\n\n\n\n\n\nprint(esol_data)\nprint(esol_data)\n\n\n\n\n\n\nTake particular note of the names of the columns (you’ll need this later).\nFYI, you can add a couple of options to the print command: n = and width = e.g. print(VARIABLE, n = 25, width = Inf) to change the number of columns and rows shown",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#exploring-the-esol-dataset",
    "href": "Workshop2.html#exploring-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Exploring the ESOL Dataset",
    "text": "Exploring the ESOL Dataset\nNow that you’ve imported the ESOL dataset, let’s take a look at what we’re dealing with.\nThis data was collected from a combination of experimental and literature-mined sources. While useful, it’s also a bit… messy.\nLet’s inspect it to see what needs cleaning!\nThree useful functions to help you explore any data frame are:\n\nhead(data) – shows you the first few rows of your data. Great for a quick peek!\nstr(data) – shows you the structure of the dataset: column names, data types, and examples.\nsummary(data) – gives you summary statistics for each column: min, max, median, and so on.\n\n\nTry this in the code box below:\nUse the following functions to explore your dataset. The # symbol can be useful for you here… in code, it means ‘comment’ and tells R not to read either itself or anything after it on the same time. When coding, it’s important to comment throughout so that both you and anyone else can understand your code.\nSo… try using the # symbol to block out any two of the functions at any one time, then select ‘run code’ to see what the other function does - and then repeat the loop for the other two functions.\n\n\n\n\n\n\n\n\n\n\nWhat should you be looking for?\nAs you explore the data, keep an eye out for:\n\nMissing values — are there any NAs?\nWeird formatting — for example, compound names in ALL CAPS or with trailing spaces\nOutliers — very large or small values that don’t seem realistic\nDuplicates — are there repeated compounds?\n\nThese are all common issues in real-world datasets, and spotting them is the first step toward fixing them!",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#cleaning-the-esol-dataset",
    "href": "Workshop2.html#cleaning-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Cleaning the ESOL Dataset",
    "text": "Cleaning the ESOL Dataset\nNow that you’ve had a chance to explore the dataset, let’s start cleaning it!\nWe’ll do this step by step using dplyr functions (you should have loaded this into the memory earlier using library(dplyr)). Your job is to fill in the blanks.\n\n\n\n\n\n\nTip\n\n\n\nTip: Use filter() to remove rows, mutate() to create or modify columns, and distinct() to remove duplicates.\n\n\nTry the code below. Fill in the blanks with the appropriate column heading name (you’ll need to remove the “____” bits first (just remember this is important that if your heading has spaces in, you’ll need to put the whole heading name between backticks i.e. `. Thebacktick ` button is often found just above the ‘tab’ button)!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nRemember, the names of the headings are: The compound names: Compound ID The logS values: ESOL predicted log solubility in mols per litre\n\n\n\n\n\n\n\n\n# Start with the original esol_data\nclean_esol &lt;- esol_data %&gt;%\n  # 1. Remove rows where logS is missing\n  filter(!is.na(`ESOL predicted log solubility in mols per litre`)) %&gt;%\n  # 2. Standardise the compound names\n  mutate(compound = tolower(trimws(`Compound ID`))) %&gt;%\n  # 3. Remove duplicate rows\n  distinct()\n\n# Start with the original esol_data\nclean_esol &lt;- esol_data %&gt;%\n  # 1. Remove rows where logS is missing\n  filter(!is.na(`ESOL predicted log solubility in mols per litre`)) %&gt;%\n  # 2. Standardise the compound names\n  mutate(compound = tolower(trimws(`Compound ID`))) %&gt;%\n  # 3. Remove duplicate rows\n  distinct()\n\n\n\n\n\n\n\nUnderstanding Each Cleaning Step\nLet’s take a moment to understand exactly what each line of the cleaning pipeline is doing…\nclean_esol &lt;- esol_data %&gt;%\nWe’re building a data cleaning pipeline using the pipe operator (%&gt;%). This means each line takes the result from the previous step and passes it forward to the next one.\nLet’s break it down step-by-step:\n\n(a) filter(!is.na(\"  \"))\nfilter(!is.na(`ESOL predicted log solubility in mols per litre`))\n\nfilter() is used to keep only certain rows of the data.\nis.na(ESOL predicted log solubility in mols per litre) checks for missing values (NAs) in the “ESOL predicted log solubility in mols per litre” column.\n!is.na(ESOL predicted log solubility in mols per litre) means “not missing”, so this line keeps only rows where there is a value for logS.\n\n\n\n(b) mutate(compound = tolower(trimws(\"   \")))\nmutate(compound = tolower(trimws(`Compound ID`)))\n\nmutate() is used to modify or create a new column.\nInside it, we’re creating a new compound column.\ntrimws() removes leading and trailing whitespace from the compound names.\ntolower() converts all characters to lowercase.\n\nTogether, this helps standardise the formatting of compound names (e.g. fixing ” ACETAMINOPHEN ” to “acetaminophen”).\n\n\n(c) distinct()\ndistinct()\n\nThe command distinct() removes duplicate rows from the data frame.\nSometimes in real datasets, the same compound appears more than once — this helps clean that up.\nIf you want to remove duplicates only based on certain columns, you can do: distinct(compound, .keep_all = TRUE).\n\n\n\n\nFinal result\nThe cleaned dataset is now stored in a new object called clean_esol. This is what you’ll use going forward in your analysis — it’s more reliable and ready for real work!",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#comparing-the-messy-and-clean-esol-data",
    "href": "Workshop2.html#comparing-the-messy-and-clean-esol-data",
    "title": "Workshop 2",
    "section": "Comparing the Messy and Clean ESOL Data",
    "text": "Comparing the Messy and Clean ESOL Data\nNow that you’ve cleaned your dataset and created esol_clean, let’s compare it to the original messy version (esol_messy) to see what’s changed.\n\n\n\n\n\n\n\n\n\n1. Compare Dimensions\nUse nrow() and ncol() to check how many rows and columns each version (i.e. esol_data and clean_esol) has. Run the code below to see what happens…\n\n\n\n\n\n\n\n\n\n\n2. Compare Summaries\nUse summary() to compare key columns (like logS (i.e. “ESOL predicted log solubility in mols per litre”) or MolWt i.e. “Molecular Weight”). Try running the code below and then the column for another.\n\n\n\n\n\n\n\n\n\n\n3. Compare Unique Compounds\nLet’s see how many unique compounds are in each dataset. Remember, earlier you created a new column called ‘compound’ when you cleaned the ‘Compound ID’ column.\n\n\n\n\n\n\n\n\n\n\nSpot Formatting Fixes\nTry printing a few rows to visually inspect any fixes to formatting.\n\n\n\n\n\n\n\n\nYou should see that names in the cleaned data are now lowercase and free of trailing spaces.\n\n\nWhat Should You Notice?\n\nFewer rows? Good! You cleaned out invalid entries or duplicates.\nImproved summaries? Excellent — weird or missing values are likely gone.\nTidier names? Formatting is more consistent for analysis or merging.\n\nYou’re now ready to move on to combine this cleaned data with another!",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "Workshop2.html#combining-datasets-using-a-shared-column",
    "href": "Workshop2.html#combining-datasets-using-a-shared-column",
    "title": "Workshop 2",
    "section": "Combining Datasets Using a Shared Column",
    "text": "Combining Datasets Using a Shared Column\nNow that you’ve had practice cleaning the ESOL dataset, it’s time to bring in a second dataset Lipophilicity and learn how to combine datasets in R!\nIn real-world data science, it’s often helpful to combine different datasets to create a richer picture of your information. Here, we’ll match compounds between datasets using a common column: the SMILES string, which uniquely encodes the structure of each molecule.\n\nWhat is SMILES?\nSMILES stands for Simplified Molecular Input Line Entry System. It’s a compact way to represent a chemical structure using a string of text (e.g., \"CCO\" for ethanol).\nBoth the ESOL and Lipophilicity datasets contain a SMILES column (actually written in lowercase in the datasets), so even if the compounds are named differently elsewhere, we can match them using this column.\nThe Lipophilicity dataset has already been imported and cleaned into the browser, just to save you the trouble! However, if you’re working in R Studio, you will need to save and use read_csv as before to read it into a dataframe (please call it clean_lipo).\nFor the browser version, as I mentioned, the cleaned dataset is already in a dataframe called: clean_lipo. Remember, your cleaned ESOL dataset is also in a dataframe called: clean_esol.\n\n\n\nJoining Two Datasets in R\nIn R, we use the dplyr::left_join() function to combine two data frames.\nHere’s what the syntax looks like:\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\nThis line says:\n\n“Take the clean ESOL data (clean_esol)…”\n“…and add matching rows from the clean Lipophilicity data (clean_lipo)…”\n“…based on the values in the SMILES column.”\n\nThe result is a new data frame (combined_data) that contains:\n\nAll rows from clean_esol\nAny matching columns from clean_lipo, added alongside\n\n\n\nWhy might some rows not match?\nRemember, not every molecule in the ESOL dataset will be found in the Lipophilicity dataset, and that’s okay! The left_join() function keeps all of the data from the left table (clean_esol), and only fills in values from clean_lipo where it finds matching SMILES codes.\nThis means we might see NAs in the Lipophilicity columns for compounds that don’t have a match… that’s completely normal!\nTry running it yourself in the blank box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nLook above!\n\n\n\n\n\n\n\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\n\n\n\n\n\n\n\n\nExploring Your Joined Data: combined_data\nNow that you’ve created a new data frame called combined_data, let’s take a moment to explore it and see what you’re working with. Use the head(), str() and summary() commands that we covered earlier to do this in the box below:\n\n\n\n\n\n\n\n\n\n\nWell Done – You’ve Completed Workshop 2!\nYou’ve just worked through a full data cleaning and wrangling workflow using real chemistry datasets — that’s no small feat! Here’s a quick recap of what you accomplished:\n✅ You successfully imported messy chemical data using readr::read_csv()\n✅ You used dplyr and tidyr to clean and wrangle your data\n✅ You learned how to spot missing values, weird formatting, and duplicates\n✅ You created new variables and standardised your data\n✅ You joined two datasets using a common key (SMILES) to create a richer dataset\n✅ You explored your cleaned, combined dataset like a pro!\n\n\n\nWhat should you take away from this tutorial?\n\nCleaning data is a vital step in any data science project — messy data leads to misleading results.\nTools like filter(), mutate(), and select() give you full control over how your data is structured.\nCombining datasets can open the door to deeper analysis, comparisons, and insight — especially in fields like chemoinformatics.\n\n\n\nLicense: This tutorial is licensed under CC BY 4.0.",
    "crumbs": [
      "Home",
      "Workshop 2"
    ]
  },
  {
    "objectID": "intro.html#quarto",
    "href": "intro.html#quarto",
    "title": "Introduction",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "intro.html#running-code",
    "href": "intro.html#running-code",
    "title": "Introduction",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n\n\n\n\n\n\nYou can add options to executable code like this\n\n\n\n\n\n\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This set of workshops will guide you from the basics of R to data analysis relevant to your field. These will support you throughout your time at Kingston University and will also provide you with an invaluable future skill."
  },
  {
    "objectID": "index.html#welcome-to-the-r-programming-workshops-for-pharmaceutical-science-and-chemistry",
    "href": "index.html#welcome-to-the-r-programming-workshops-for-pharmaceutical-science-and-chemistry",
    "title": "Home",
    "section": "",
    "text": "This set of workshops will guide you from the basics of R to data analysis relevant to your field. These will support you throughout your time at Kingston University and will also provide you with an invaluable future skill."
  },
  {
    "objectID": "index.html#workshops",
    "href": "index.html#workshops",
    "title": "Home",
    "section": "Workshops",
    "text": "Workshops\n\n\n\n\n\n\n\n\nWorkshop\nTitle\nSkills Learned\n\n\n\n\n1\nR You Ready? Getting Started with Chemistry Data!\nIntroduction to R Basic syntax Simple plotting\n\n\n2\nData in a Lab Coat: Cleaning and Wrangling Your Chemistry Data\nImporting data using readr\nData cleaning and manipulation using dplyr\n\n\n3\nPlotting Power! Visualizing Your Data Like a Pro\nComplex visualizations for scientific data Advanced ggplot2 visualizations\n\n\n4\nMake It Match! The Magic of Correlation and Regression\nPerforming correlation and linear regression analysis\n\n\n5\nTox Talk: Exploring Toxicity Data with Statistics\nIntroduction to using R for statistical tests for comparing groups (e.g., t-tests, ANOVA)\n\n\n6\nStatistics Are Sexy: Hypothesis Testing and p values\nIntroduction to the use of R for hypothesis testing and interpreting p-values\n\n\n7\nIt’s All About the Data: Big Data in Chemistry\nIntroduction to big data analysis using R\n\n\n8\nChemical Reactions and Functions: R-ing the Curve!\nApplying functions and curve fitting to real-world chemical data\n\n\n9\nThe Plot Thickens: Beautiful Data Visualization\nAdvanced ggplot2 techniques for data visualization\n\n\n10\nStatistical Sherlock: Investigating Toxicity with Statistics\nConducting statistical hypothesis testing to compare experimental groups"
  },
  {
    "objectID": "index.html#examples-where-r-is-used-in-chemistry-pharmaceutical-science",
    "href": "index.html#examples-where-r-is-used-in-chemistry-pharmaceutical-science",
    "title": "Home",
    "section": "Examples where R is used in Chemistry & Pharmaceutical Science",
    "text": "Examples where R is used in Chemistry & Pharmaceutical Science\nThe following is a collection of journal articles (links to!) where R has been critical in pushing forwards the boundaries of science in the following contexts (this list will be extended as we go on!):\n\nAnalytical Chemistry\n\nExploratory multivariate analysis using R Language for method development in liquid chromatography | Analytical and Bioanalytical Chemistry (https://link.springer.com/article/10.1007/s00216-024-05705-y?)\nUtilizing High-Resolution Mass Spectrometry Data Mining Strategy in R Programming Language for Rapid Annotation of Absorbed Prototypes and Metabolites of Gypenosides | Molecules (https://www.mdpi.com/1420-3049/30/4/779)\n\n\n\nMedicinal Chemistry\n\nThe Use of the R Language for Medicinal Chemistry Applications | Bentham Science (https://www.eurekaselect.com/article/48427)\n\n\n\nPharmacokinetics\n\nDesign Evaluation and Optimization of Population Pharmacokinetics Model Using an R Package PopED (https://www.mdpi.com/2227-7390/11/21/4407)\nEnabling transparent toxicokinetic modeling for public health risk assessment | PLOS One (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0321321)\n\n\n\nFormulations\n\nAI-Driven Pharmaceutical Data Analysis Tool for Drug Formulation Development | Journal of Pharmaceutical Innovation (https://link.springer.com/article/10.1007/s12247-025-10203-4)"
  },
  {
    "objectID": "index.html#useful-r-packages",
    "href": "index.html#useful-r-packages",
    "title": "Home",
    "section": "Useful R packages",
    "text": "Useful R packages\n\ntidyverse\nPurpose: Data manipulation, cleaning, and visualization (includes dplyr, tidyr, ggplot2).\n\n\n\nggplot2\nPurpose: Grammar of graphics for high-quality plots of chemical and pharmaceutical data.\n\n\n\nplotly\nPurpose: Interactive visualization for complex datasets.\n\n\n\nshiny\nPurpose: Building interactive web apps for chemical data dashboards.\n\n\n\nreadr\nPurpose: Fast and friendly functions for reading rectangular data (CSV, TSV)\n\n\n\nreadxl\nPurpose: Import Excel files without external dependencies.\ntidyr\nPurpose: Reshape messy data into tidy format (long vs wide).\ndplyr\nPurpose: Grammar of data manipulation (filter, select, mutate, summarise)."
  },
  {
    "objectID": "Workshop1.html#welcome-to-workshop-1-r-you-ready-getting-started-with-chemistry-data",
    "href": "Workshop1.html#welcome-to-workshop-1-r-you-ready-getting-started-with-chemistry-data",
    "title": "Workshop 1",
    "section": "Welcome to Workshop 1: R You Ready? Getting Started with Chemistry Data!",
    "text": "Welcome to Workshop 1: R You Ready? Getting Started with Chemistry Data!",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#objectives",
    "href": "Workshop1.html#objectives",
    "title": "Workshop 1",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this workshop, you be able to:\n\nUse basic R commands to handle data\nPerform simple calculations\nCreate basic plots (using ggplot2)",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#why-is-r-important-for-you",
    "href": "Workshop1.html#why-is-r-important-for-you",
    "title": "Workshop 1",
    "section": "Why is R important for you??",
    "text": "Why is R important for you??\nChemical Data Analysis & Predictive Modeling: Chemists often work with large datasets from spectroscopy, chromatography, and molecular simulations. R helps analyze trends, optimize reactions, and predict properties with machine learning.\nAdvanced statistical analysis: R is one of the most important software packages available for statistical analyses, including hypothesis testing, regression, multivariate analysis and thus is ideal for pharmaceutical science and chemical data processing (e.g. stability testing, reaction rate analysis etc.).\nMolecular & Drug Design Applications: R aids in computational chemistry by supporting quantum chemistry calculations, molecular docking, and cheminformatics.\nPharmaceutical Formulation & Development: Pharmaceutical scientists use R to model drug solubility, stability, and formulation optimization.\nData visualisation and graphing: R is the gold standard for drawing customisable and eye-catching graphs.. This is likely to be useful for you throughout your career, irrelevant of the field you move into!",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#format-of-workshops",
    "href": "Workshop1.html#format-of-workshops",
    "title": "Workshop 1",
    "section": "Format of workshops",
    "text": "Format of workshops\nYou will need to type any text in the grey boxes into the ‘Console’ region of R Studio.\nTry executing the text below by typing it in the Console area where you see a &gt; and then pressing Enter.\n\n\n\n\n\n\n\n\nThe plot that you’ve generated (well done) shows the effect of vitamin C on the tooth growth in guinea pigs. You can read more (if you’re interested!) at: https://doi.org/10.1093/jn/33.5.491.\nAs we go through each week, you will learn how to use a wide range of valuable tools including tools that support: (i) Data cleaning and manipulation (ii) Data plotting incl. complex visualisations for scientific data (iii) Statistical tests & correlation and regression analysis (iv) Big data analysis. These will all be put into relevant (if occasionally slightly implausible!) pharmaceutical and chemical scenarios.",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#your-first-r-command",
    "href": "Workshop1.html#your-first-r-command",
    "title": "Workshop 1",
    "section": "Your first R command",
    "text": "Your first R command\nIn the Console region, enter the following: 2 + 2 and then run it (remember, you may / will need either to click the Run button or press Ctrl+Shift+Enter… but sometimes just pressing Enter works just as well!).\nThe output should be produced directly below your entry!",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#key-concepts-in-r",
    "href": "Workshop1.html#key-concepts-in-r",
    "title": "Workshop 1",
    "section": "Key Concepts in R",
    "text": "Key Concepts in R\nWelcome to your first real steps in R. In this section, you’ll learn some of the most important ideas for working with data in R. We’ll use examples relevant to pharmaceutical science and chemistry — so everything here connects to the kind of work you’ll be doing in labs, coursework, or research later in your degree.\nIf you’re following along in RStudio (which you should be), try typing each code example into the Console (or a script file) and observe the output. You’re encouraged to experiment… try changing values or adding new examples.\nWe’ll cover:\n\nVariables\nData types\nVectors",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#data-frames",
    "href": "Workshop1.html#data-frames",
    "title": "Workshop 1",
    "section": "Data frames",
    "text": "Data frames\n\n1. Variables\nA variable is like a labelled container that stores a piece of information — a number, a name, a result — so that you can use it later.\nIn R, we assign values to variables using the assignment arrow &lt;-. You read this as “gets” or “is assigned”.\nTry this:\n\ndose &lt;- 50\n\nThis creates a variable called dose and gives it the value 50 (maybe it’s 50 mg of a drug).\nNow type:\n\ndose\n\n[1] 50\n\n\nR will show you what’s stored in that variable.\nTry it yourself: Create a variable called temperature and assign it a value of 37. Then print it.\n\ntemperature &lt;- 37\ntemperature\n\n[1] 37\n\n\nYou can name variables almost anything you like, but it’s good practice to use names that make sense for your data.\n\n\n\n2. Data Types\nNot all variables are the same. Some store numbers, some store words, and some just keep track of whether something is true or false.\nHere are the most common types of data in R:\n\nNumeric: numbers (e.g., concentrations, pH, temperature)\nCharacter: text or words (e.g., compound names, sample labels)\nLogical: TRUE or FALSE values (e.g., was the drug effective?)\n\nTry these examples:\n\n# Numeric\nconcentration &lt;- 25.5\n\n# Character (text)\ncompound &lt;- \"Aspirin\"\n\n# Logical (TRUE/FALSE)\neffective &lt;- TRUE\n\nYou can check the type of data using the class() function:\n\nclass(concentration)\n\n[1] \"numeric\"\n\nclass(compound)\n\n[1] \"character\"\n\nclass(effective)\n\n[1] \"logical\"\n\n\nTry changing the values and rerun class() to see how R handles different inputs.\n\n\n\n3. Vectors\nA vector is a list of values, all of the same type, stored together in one object. If a variable is a single value, a vector is a series of them. This is really useful when you’re collecting data from repeated measurements.\nLet’s say you measure drug concentration over time. You could store those concentrations in a vector like this:\n\nconcentrations &lt;- c(10, 20, 30, 40, 50)\n\nThe c() function means “combine” — it tells R to combine these values into a single vector.\nNow print it:\n\nconcentrations\n\n[1] 10 20 30 40 50\n\n\nYou can get individual values from a vector using square brackets:\n\nconcentrations[1]   # first value\n\n[1] 10\n\nconcentrations[3]   # third value\n\n[1] 30\n\n\nTry it yourself: Create a vector of pH measurements: 6.5, 6.7, 6.8, 6.9, 7.0\n\npH_values &lt;- c(6.5, 6.7, 6.8, 6.9, 7.0)\npH_values\n\n[1] 6.5 6.7 6.8 6.9 7.0\n\n\n\n\n\n4. Data Frames\nA data frame is like a spreadsheet in R — it’s a table where each column is a variable (stored as a vector), and each row is an observation. This is the format you’ll often use to store real experimental data.\nLet’s say you’re studying how the concentration of a drug changes over time. You collect measurements at five time points. Here’s how you could store that data:\n\ndata &lt;- data.frame(\n  Time = c(0, 1, 2, 3, 4),\n  Concentration = c(50, 40, 30, 20, 10)\n)\n\nTo see the full table, type:\n\nprint(data)\n\n  Time Concentration\n1    0            50\n2    1            40\n3    2            30\n4    3            20\n5    4            10\n\n\nYou should see a tidy table with two columns: Time and Concentration.\nTo access a single column of the data frame, use the $ operator:\n\ndata$Concentration\n\n[1] 50 40 30 20 10\n\n\nTo get a specific value (e.g., row 2, column 2):\n\ndata[2, 2]\n\n[1] 40\n\n\nTry it yourself: What is the concentration at time = 3 hours? (Hint: Look at row 4.)\n\n\n\nPractice Task\nLet’s try making a new data frame. Here’s a small dataset from a made-up drug trial:\n\n\n\nCompound\nDose (mg)\nEffective?\n\n\n\n\nAspirin\n100\nTRUE\n\n\nIbuprofen\n200\nFALSE\n\n\n\nCreate this in R:\n\ncompounds &lt;- data.frame(\n  Compound = c(\"Aspirin\", \"Ibuprofen\"),\n  Dose = c(100, 200),\n  Effective = c(TRUE, FALSE)\n)\n\n\nprint(compounds)\n\n   Compound Dose Effective\n1   Aspirin  100      TRUE\n2 Ibuprofen  200     FALSE\n\n\nNow try:\n\nPrinting just the Dose column\nChecking the class of the Effective column\nChanging one of the doses to a different value and printing the result again\n\n\n\n\nSummary\nIn this section, you’ve learned the basics of:\n\nVariables – how to assign and use them\nData types – numeric, character, and logical values\nVectors – how to store multiple values in a single object\nData frames – how to organise structured data in a table\n\nThese concepts will be used throughout the rest of this workshop, including in plotting and data analysis. Getting comfortable with them now will make everything else much easier later.\nIf you’ve followed along and typed the code yourself, well done… that’s the best way to learn!",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#simple-calculations-with-r",
    "href": "Workshop1.html#simple-calculations-with-r",
    "title": "Workshop 1",
    "section": "Simple Calculations with R",
    "text": "Simple Calculations with R\nIn this section, we’ll look at how to perform some basic but essential calculations in R. These are the kinds of operations you’ll use frequently when analysing pharmaceutical or chemical data — such as calculating averages, variability, and comparing conditions.\n\n\nAverage Drug Concentration\nLet’s start with a simple scenario: you’ve measured the concentration of a drug in the bloodstream at five different time points.\nWe want to calculate the average concentration.\n\n# Concentration measurements over time (in mg/L)\nconcentration &lt;- c(50, 40, 30, 20, 10)\n\nNow calculate the mean using the mean() function:\n\navg_conc &lt;- mean(concentration) \ncat(\"Average concentration:\", avg_conc, \"mg/L\")\n\nAverage concentration: 30 mg/L\n\n\nThe mean() function calculates the arithmetic average of the values in the vector. In case you’re wondering about the cat() function, in R it’s used to print text and values together in a readable format, all on one line, without the extra formatting that other functions (like print() or just typing a variable name) might include. In essence, cat() stands for concatenate and print!\n\n\n\nDiscussion\nWhy might it be useful to calculate the average concentration of a drug over time?\nThink about how this information might be used in:\n\nDetermining dosing intervals\nAssessing therapeutic effectiveness\nComparing different formulations or delivery methods\n\nDiscuss these points with another student.\n\n\n\nVariability: Standard Deviation\nWe can also assess how much the concentration varies across these measurements. This is where standard deviation is useful since it gives us a measure of spread or variability.\n\nsd_conc &lt;- sd(concentration) \ncat(\"Standard deviation of concentration:\", sd_conc)\n\nStandard deviation of concentration: 15.81139\n\n\nA higher standard deviation = more variability in measurements. A lower standard deviation = more consistency.\n\n\n\nTry It Yourself\nNow try entering your own concentration data and calculate the average and standard deviation.\nChange a value or two and observe how the results change.\n\n# Enter your own values here:\nyour_conc &lt;- c(52, 49, 48, 51, 50)\n\n# Calculate mean and standard deviation\nmean(your_conc) \n\n[1] 50\n\nsd(your_conc)\n\n[1] 1.581139\n\n\n\n\n\nSummary\nIn this section, you have:\n\nCreated a numeric vector\nCalculated the mean and standard deviation\nStarted thinking about how to interpret these in the context of pharmaceutical data\n\nThese are fundamental tools for any kind of data analysis and you’re now equipped to start using them in R.",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#plotting-data-with-ggplot2",
    "href": "Workshop1.html#plotting-data-with-ggplot2",
    "title": "Workshop 1",
    "section": "Plotting Data with ggplot2",
    "text": "Plotting Data with ggplot2\nVisualising data is one of the most important steps in any analysis. It helps you understand trends, detect problems, and communicate results clearly.\nIn pharmaceutical science, plotting concentration over time is a key part of understanding drug absorption, distribution, and elimination.\nIn this section, you’ll learn how to use the ggplot2 package to create a basic scatter plot and line graph.\n\n\nStep 1: Load the ggplot2 package\nIf this is the first time you’re using ggplot2, make sure it’s installed:\ninstall.packages(\"ggplot2\")\nNow load the package:\n\n\n\nStep 2: Create a simple data frame\nLet’s use a small dataset showing how drug concentration changes over 5 hours:\n\n# Create a data frame with time and concentration\n\ndata &lt;- data.frame( Time = c(0, 1, 2, 3, 4), Concentration = c(50, 40, 30, 20, 10) )\n\nYou can print the data frame to check it:\n\nprint(data)\n\n  Time Concentration\n1    0            50\n2    1            40\n3    2            30\n4    3            20\n5    4            10\n\n\n\n\n\nStep 3: Plot the data\nWe’ll now create a scatter plot showing Concentration vs. Time, and then connect the points with a line to show the trend.\n\n\n\n\n\n\n\n\nYou should see a plot that shows the drug concentration decreasing over time, a common pharmacokinetic pattern.\n\n\n\nWhat’s Happening Here?\naes(x = Time, y = Concentration): tells ggplot which variables to plot.\ngeom_point(): adds points to the graph.\ngeom_line(): draws lines between the points.\nlabs(): adds a title and axis labels.\n\n\n\nTry This Yourself\n\nChange one of the concentration values and run the plot again. What happens to the shape of the curve?\nAdd more time points to the data frame.\nTry removing geom_line() — how does that change the interpretation?\nAdd a new patient or condition and compare their profiles side-by-side (optional – challenge task).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\nIn this section, you’ve learned how to:\n\nCreate a data frame in R\nUse ggplot2 to plot numerical data\nLabel and customise a basic plot\n\nPlotting is one of the most powerful ways to understand your data. With ggplot2, it’s easy to build on this foundation as your analysis becomes more complex - we’ll come back to this in future workshops, as well as learning about more technical plotting tools.",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop1.html#overarching-summary",
    "href": "Workshop1.html#overarching-summary",
    "title": "Workshop 1",
    "section": "Overarching summary",
    "text": "Overarching summary\nIn this section, you learned how to:\n\nUse the ggplot2 package to create clear, informative plots\nBuild a basic scatter plot and line graph from your data\nLabel your axes and add a title to make your plot easy to understand\n\nVisualising data helps you spot patterns and trends, for example, how drug concentration changes over time. This is an essential skill in pharmaceutical science and chemistry, and you’ll be using it a lot more as your datasets get bigger and more complex.\nRemember: if your code isn’t working, check that the ggplot2 package is installed and loaded using library(ggplot2) before plotting.",
    "crumbs": [
      "Home",
      "Workshop 1"
    ]
  },
  {
    "objectID": "Workshop3_ggplot-themes.html",
    "href": "Workshop3_ggplot-themes.html",
    "title": "Labels, Themes and Faceting",
    "section": "",
    "text": "Once you’ve made a plot, it’s important to make it clear and easy to read. In this section, we’ll learn how to add informative titles and axis labels, improve the overall look with themes, and break plots into multiple panels using faceting. These techniques help highlight patterns in the data and make your plots more professional and easier to interpret.\n\nLabels\n\nAdding and improving labels\nGood labels make plots readable and informative. Let’s take the original scatter plot that we make and change & add labels to make it a bit more clear:\n\n\n\n\n\n\n\n\nThe command labs() has several arguments, including:\n\ntitle which gives the plot a main title,\ncaption which is typically used to provide information about the data source,\nx for the x-axis label, and\ny the y-axis label.\n\nIn ggplot2, you can customize the size, colour, and style of labels and text using the theme() function…\n\n\n\nThemes\nThemes control the overall appearance of a plot, including background, grid lines, and text styles. Using a theme like theme_minimal() or theme_classic() can make your plots cleaner and easier to read, and you can further customize fonts, colours, and spacing to improve clarity.\nThe default theme is theme_grey() but there are several others e.g.:\n\ntheme_bw()\ntheme_linedraw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\n\nThere are also more than seventy other themes in additional packages (but don’t worry about these for now!).\nIn the example below, the theme has been changed to theme_minimal():\n\n\n\n\n\n\n\n\nTry it yourself! In the box below, copy the command from above and change the theme to theme_void():\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nSimply change theme_minimal() to theme_void().\n\n\n\n\n\n\n\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`)) + geom_point() +\n  labs(\n    title = \"Solubility vs Molecular Weight\",\n    x = \"Molecular Weight (g/mol)\",\n    y = \"Measured Log Solubility\",\n    caption = \"Data from solubility measurements\"\n  ) +\n  theme_void()\nggplot(data, aes(x = `Molecular Weight`, y = `measured log solubility in mols per litre`)) + geom_point() +\n  labs(\n    title = \"Solubility vs Molecular Weight\",\n    x = \"Molecular Weight (g/mol)\",\n    y = \"Measured Log Solubility\",\n    caption = \"Data from solubility measurements\"\n  ) +\n  theme_void()\n\n\n\n\n\n\nNow you’ve got the hang of this, try changing the theme to some of the other options, including theme_classic().\nAs mentioned earlier, we can also use theme() to change the size, colour, location etc. of the labels, as illustrated in:\n\n\n\n\n\n\n\n\nThere’s a lot more than can be done with themes… if you wish to learn more, see: ggplot2-themes.\n\n\nFaceting (panels)\nFaceting splits a plot into multiple panels based on the levels of one or more categorical variables, so you can compare patterns across groups. It’s a powerful way to show subplots side by side without overloading a single plot with too much information.\nLet’s try splitting our original scatter plot into multiple smaller panels based on the number of rings:\n\n\n\n\n\n\n\n\nThe argument facet_wrap(~ VARIABLE) creates a grid of plots, one per level.\nIn case you’re surprised by the fact that some compounds seem to have a surprisingly large number of rings… the two points in the ‘Number of Rings = 8’ panel both correspond to digitoxin (under slightly different conditions), which has a rather complex structure:\n\n\n\nChemical structure of digitoxin\n\n\nWe can take this even further and facet by two variables… however, this dataset doesn’t really lend itself to this.\n\n\nSummary\nYou’ve learned how to explore your data using histograms, density plots, scatterplots, boxplots, and violin plots, including ways to add jittered points to reveal individual observations. You’ve also covered how to improve clarity by adding informative titles, axis labels, and legends, customizing text and themes, and using faceting to split plots into multiple panels for easier comparison.\nMany of these functions are not possible in Excel - actually, we’ve only just explored the tip of the iceberg… there’s far, far more that we can do with ggplot2.",
    "crumbs": [
      "Home",
      "Workshop 3",
      "Labels, Themes and Faceting"
    ]
  },
  {
    "objectID": "Workshop3_introduction.html#welcome-to-workshop-3-plotting-power-visualizing-your-data-like-a-pro",
    "href": "Workshop3_introduction.html#welcome-to-workshop-3-plotting-power-visualizing-your-data-like-a-pro",
    "title": "Introduction to Workshop 3",
    "section": "Welcome to Workshop 3: Plotting Power! Visualizing Your Data Like a Pro",
    "text": "Welcome to Workshop 3: Plotting Power! Visualizing Your Data Like a Pro\nThis workshop will go through how R can help you visualise molecular properties and explore relationships in scientific data. We’ll be focusing on solubility but of course everything learnt here will also be applicable to other datasets!\n\nWhat you’ll be learning\nIn this workshop, you will learn how to:\n\nLoad data and create a basic plot (ggplot)\nExplore your data using different plot types including histograms, boxplot and trendlines\nUse graphing themes and faceting to improve clarity and visualisation\nInterpret patterns in your data\n\n\n\nWhy does this matter?\n\nVisualisation is essential for understanding structure–property relationships.\nSolubility affects absorption, formulation and drug design decisions.\nData skills are increasingly expected in modern chemical and pharmaceutical research.",
    "crumbs": [
      "Home",
      "Workshop 3",
      "Introduction to Workshop 3"
    ]
  },
  {
    "objectID": "Workshop4_Rscript1.html",
    "href": "Workshop4_Rscript1.html",
    "title": "Conditional if/else statements",
    "section": "",
    "text": "In this section, you’ll be developing an R script to determine whether a certain mass of chemical can fully be dissolved in a certain volume of solvent (assume water, unless otherwise stated) based on its known solubility.\nYou’ll also be using some conditional statements, here if and else statements in order to generate a certain outcome depending on the scenario. Conditional statements are the backbone of coding, so very useful to get to grips with as early as possible!\n\nWhat are if/else statements?\nIn everyday life, we make decisions based on conditions all the time:\n\nIf it’s raining, I’ll take an umbrella.\nIf the solution is cloudy, I need to mix it more.\nIf the mass is greater than the solubility limit, not everything will dissolve.\n\nProgramming languages need a way to do exactly the same thing i.e. to choose between different actions depending on a situation.\nThat’s what if/else statements are for.\nAn if/else statement lets your program ask a question and make a decision:\n\nIf some condition is true → do one thing\nElse (meaning “otherwise”) → do something else\n\nIt’s a simple decision-making tool for your code.\n\nThe structure of an if/else statement in R\nHere’s the pattern:\nif (condition) {\n  # Code that runs when the condition is TRUE\n} else {\n  # Code that runs when the condition is FALSE\n}\nR checks the condition once, then chooses a path.\n\n\nWhy should you care?\nChemistry is full of conditional decisions:\n\nWill this dissolve or not?\nIs the concentration too high?\nIs the temperature above the melting point?\nIs this reaction complete?\n\nYou can turn these real lab questions into code using if/else.\nFor example:\nif (mass_added &lt;= max_dissolved) {\n  cat(\"All of it will dissolve.\")\n} else {\n  cat(\"Some will remain undissolved.\")\n}\nThis is literally the same reasoning you apply in the lab, just automated!\n\n\n\n\n\n\nNote\n\n\n\nRemember: cat() prints text or values to the screen and concatenates them together into one continuous, readable message.\n\n\n\n\n\nWebR Testing if/else statements\nLet’s try a tiny example first, so you can see if/else statements in action… here is some code below.\nACTIVITY: Try running the code below as it is:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe \\n in the cat() commands is an escape sequence (a special combination of characters that represents something not easily typed or non-printable). Specifically, \\n represents a call for a new line to be generated in the output (like pressing the ‘Enter’ key, in coding language).\n\n\nACTIVITY: Now edit the value for x in the code above to be 30 (rather than 10). Run the code again. What happens?\n\n\nWebR Applying conditional statements\nIn this section, we (or rather you) are trying to create a short R script file that will determine whether the proposed mass of a chemical (here, called mass_added) for dilution (in a certain volume) will result in the chemical fully dissolving or not. In the latter eventuality, this means that the mass proposed is greater than the mass limit for that volume of solvent (here, called max_dissolved).\nThe ‘condition’ (using an if/else statement) should therefore be:\nif (mass_added &lt;= max_dissolved) {\n  # everything dissolves\n} else {\n  # some remains undissolved\n}\nWe do, however, also need to calculate the value of max_dissolved from known (i.e. published) solubility values, and the desired volume. This little code snippet does this:\n\n\n\n\n\n\n\n\nIn the code above, the unknown chemical has a known solubility limit of 14 mg/mL and there is 100 mL solvent.\nACTIVITY: Run the code above to determine the maximum mass of the unknown chemical that can be dissolved.\nEXPERIMENT: Caffeine has moderate solubility in water of 22 mg/mL at room temperature. Assuming that the average coffee mug has a volume of 250 mL, modify the code below to determine what the maximum amount of caffeine is that can be dissolved in a coffee cup’s worth of water.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nYou will need to edit the numbers for solubility and volume.\n\n\n\n\n\n\n\n# Example numbers \nsolubility &lt;- 22  # mg/mL\nvolume &lt;- 250     # mL\n\n# Calculation\nmax_dissolved &lt;- solubility * volume\n\ncat(\"Maximum that can dissolve is:\", max_dissolved, \"mg\\n\")\n# Example numbers \nsolubility &lt;- 22  # mg/mL\nvolume &lt;- 250     # mL\n\n# Calculation\nmax_dissolved &lt;- solubility * volume\n\ncat(\"Maximum that can dissolve is:\", max_dissolved, \"mg\\n\")\n\n\n\n\n\n\nWe can now put both of these parts together and add a variable that represents the proposed mass (i.e. mass_added).\nMake sure you can understand all of lines of the code in the code snippet below.\n\n\n\n\n\n\n\n\nEXPERIMENT: Furosemide (a diuretic) has quite poor solubility in water of 0.055 mg/mL at room temperature. Edit the code above to determine whether 30 mg of furosemide will dissolve fully in 1 L (i.e. 1000 mL) of water or not.\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nYou will need to edit the numbers for solubility and volume.\n\n\n\n\n\n\n\n# Example numbers \nsolubility &lt;- 0.055  # mg/mL\nvolume &lt;- 1000     # mL\n\n# Calculation\nmax_dissolved &lt;- solubility * volume\n\nmass_added &lt;- 30  # mg \n\nif (mass_added &lt;= max_dissolved) {\n  cat(\"All of it will dissolve!\\n\")\n} else {\n  cat(\"Some will remain undissolved.\\n\")\n}\n# Example numbers \nsolubility &lt;- 0.055  # mg/mL\nvolume &lt;- 1000     # mL\n\n# Calculation\nmax_dissolved &lt;- solubility * volume\n\nmass_added &lt;- 30  # mg \n\nif (mass_added &lt;= max_dissolved) {\n  cat(\"All of it will dissolve!\\n\")\n} else {\n  cat(\"Some will remain undissolved.\\n\")\n}\n\n\n\n\n\n\n\n\nThe readline() command\nSometimes, your script needs information from you e.g. the name of a compound, how much mass you added or the volume of solvent.\nThat’s what readline() does:\n\nIt pauses the script and shows a prompt message.\nYou type your answer and press Enter.\nThe script remembers what you typed so it can use it in calculations.\n\nA typical example of readline() in use is given below:\ndrug_name &lt;- readline(prompt = \"Enter the name of the compound: \")\nIt should be emphasised that this command isn’t suitable for this simple browser environment but works beautifully in RStudio!\n\n\nRStudio A Solubility Checker R Script\nACTIVITY: In RStudio, open a new R script file, copy the code below and save it as: Solubility_checker.R.\n\n\n\n\n\n\nNote\n\n\n\nRemember, you don’t need to write the ‘.R’ in the name as it will automatically save as an R file, assuming that you’ve chosen the correct option).\n\n\n# =================================================\n# Script 1: Solubility Check - Interactive Version\n# =================================================\n\n# This script calculates whether a given mass of a compound\n# will fully dissolve in a certain volume of solvent.\n\n# ----------------------------------------\n# STEP 1: Ask the user for input\n# ----------------------------------------\ndrug_name &lt;- readline(prompt = \"Enter the name of the compound: \")\nsolubility &lt;- as.numeric(readline(prompt = \"Enter solubility (mg/mL): \"))\nvolume &lt;- as.numeric(readline(prompt = \"Enter volume of solvent (mL): \"))\nmass_added &lt;- as.numeric(readline(prompt = \"Enter mass of compound added (mg): \"))\n\n# ----------------------------------------\n# STEP 2: Calculate maximum dissolvable mass\n# ----------------------------------------\nmax_dissolved &lt;- solubility * volume\n\n# ----------------------------------------\n# STEP 3: Check if the mass added will fully dissolve\n# ----------------------------------------\nif (mass_added &lt;= max_dissolved) {\n  cat(\"All of the\", drug_name, \"will dissolve!\\n\")\n} else {\n  cat(\"Some of the\", drug_name, \"will remain undissolved.\\n\")\n  cat(\"Maximum mass that can dissolve is:\", max_dissolved, \"mg\\n\")\n}\nWhen you use readline(), the value you type is always stored as text (a “string”), even if it looks like a number.\nSince, computers treat text differently from numbers, if you try to do any calculations with text, R will give an error.\nThe as.numeric() command simply converts text into a number so that R can do calculations.\nACTIVITY: Now click ‘Source’ to run the whole code, and use it to determine whether a sugar cube, which has a mass of 4.0 grams and a solubility of 2000 mg/mL in water at room temperature, can fully dissolve in 10 mL of water.\nThe video below shows a quick run-through of this!\n\n\nSection summary\nYou’ve learned how to use if/else statements. Just in case you’re wondering, you can use just an if statement without an else clause - in the case where the the condition is FALSE, R simply skips the code inside if() and continues with the rest of the script.\nIn the next section, you’ll write a whole script yourself!",
    "crumbs": [
      "Home",
      "Workshop 4",
      "Conditional if/else statements"
    ]
  },
  {
    "objectID": "Workshop4_introduction.html",
    "href": "Workshop4_introduction.html",
    "title": "Introduction to Workshop 4",
    "section": "",
    "text": "Welcome to the “Write your own R Scripts” workshop! Now that you’ve got some of the basics of R under your belt, in this session, you’ll learn how to create your very first R script files to perform chemical and pharmaceutical calculations. We’ll focus on two core tasks:\n\nchecking how much of a compound can dissolve in a given volume of solvent, and\ncalculating dilutions using the familiar C₁V₁ = C₂V₂ formula.\n\nBy the end of the workshop, you’ll be able to write, save and run your own scripts, turning manual lab calculations into reproducible, automated tools.\n\n\nIn this workshop, you will learn how to:\n\nCreate and save R script files\nPrint results clearly using cat() or similar functions\nUse interactive input with readline() to make scripts dynamic\nStructure a script with comments to make it readable and reusable\nUse conditional statements (if/else)\n\n\n\n\nFollowing this workshop, you should be able to turn manual lab calculations into reproducible, automated tools using R. By learning to write your own scripts, you’ll save time, reduce errors, and gain a skill that’s directly applicable to chemistry and pharmaceutical work and sets the foundation for more advanced data analysis later.\nI’ll be using two badges: WebR and RStudio to denote whether the text (and tasks for you to work through) relates to the browser (this is WebR) or RStudio.",
    "crumbs": [
      "Home",
      "Workshop 4",
      "Introduction to Workshop 4"
    ]
  },
  {
    "objectID": "Workshop4_introduction.html#welcome-to-workshop-4-writing-your-own-r-scripts-turning-lab-calculations-into-code",
    "href": "Workshop4_introduction.html#welcome-to-workshop-4-writing-your-own-r-scripts-turning-lab-calculations-into-code",
    "title": "Introduction to Workshop 4",
    "section": "",
    "text": "Welcome to the “Write your own R Scripts” workshop! Now that you’ve got some of the basics of R under your belt, in this session, you’ll learn how to create your very first R script files to perform chemical and pharmaceutical calculations. We’ll focus on two core tasks:\n\nchecking how much of a compound can dissolve in a given volume of solvent, and\ncalculating dilutions using the familiar C₁V₁ = C₂V₂ formula.\n\nBy the end of the workshop, you’ll be able to write, save and run your own scripts, turning manual lab calculations into reproducible, automated tools.\n\n\nIn this workshop, you will learn how to:\n\nCreate and save R script files\nPrint results clearly using cat() or similar functions\nUse interactive input with readline() to make scripts dynamic\nStructure a script with comments to make it readable and reusable\nUse conditional statements (if/else)\n\n\n\n\nFollowing this workshop, you should be able to turn manual lab calculations into reproducible, automated tools using R. By learning to write your own scripts, you’ll save time, reduce errors, and gain a skill that’s directly applicable to chemistry and pharmaceutical work and sets the foundation for more advanced data analysis later.\nI’ll be using two badges: WebR and RStudio to denote whether the text (and tasks for you to work through) relates to the browser (this is WebR) or RStudio.",
    "crumbs": [
      "Home",
      "Workshop 4",
      "Introduction to Workshop 4"
    ]
  },
  {
    "objectID": "Workshop4_Rscript0.html",
    "href": "Workshop4_Rscript0.html",
    "title": "Script 0: Hello, World!",
    "section": "",
    "text": "R Script Structure\nUnlike some computing languages (e.g. C/C++, Java, Fortran), which are ‘compiled’ languages, R (and also e.g. Python) is an interpreted scripting language and hence:\n\nDOESN’T need a ‘main()’ function.\nDOESN’T need explicit ‘start’ or ‘end’ statements.\nInstead, commands are just written top-to-bottom.\n\nComments (shown as lines starting with #) are ignored by R but are VERY helpful for people (including yourself when you revisit it!) reading your code. This makes R scripts very simple to modify and re-run!\n\n\n\n\n\n\nImportant\n\n\n\nIt is CRITICAL to choose sensible names for variables… together with comments, this helps your script be easily readable.\n\n\nOne last thing… R scripts can be run either all at once or line by line. User’s choice.\n\n\nWebR Your first R script: Hello, World!\nLet’s start with a very small starter script. In traditional programming, the first script is often “Hello, World!”, so let’s stick to that tradition:\n\n\n\n\n\n\n\n\nACTIVITY: Run the code above.\nOnce you’ve checked that it works here (you should see text stating ‘Hello, World!’ that’s appeared just above this sentence) after you used the ‘Run Code’ button (in the browser), do the following:\nACTIVITY: Follow the steps below to create a new R script file.\n\n\nRStudio Create a new R script file\n\nLaunch RStudio (you will need to use AppsAnywhere if using a KU computer)\nClick on File → New File → R Script (or press Ctrl+Shift+N / Cmd+Shift+N).\n\nA short video of this is shown below:\n\n\n\nRStudio Write an R script\nIn this particular case, the code that you need is given in the sub-section Hello, World! above.\nACTIVITY: Copy and paste the “Hello, World!” R code above into the blank area (called the “editor pane”) that has appeared in the top left quarter of RStudio. i.e.:\n\n\n\nRStudio Save as an R script file\nNow you can save this file! Let’s call it ‘RScript0’.\nACTIVITY: Follow the steps below to save your R script file.\n\nClick on File → Save As… which will bring up the Save File window.\nEnter a filename (here: RScript0)\nCheck to make sure that ‘R’ is written in the ‘Save As Type’ box\nClick ‘Save’.\n\nThe short video below shows this in action:\n\nYou now have a persistent R script file that you can close and re-open any time, well done!\n\n\nRStudio Run an R script file\nAbove the editor pane, there is a row of clickable buttons i.e.:\n The buttons allow you to do the following:\nRun – The Run button executes the current line of code where the cursor is, or any code you have selected. It’s useful for testing small sections of a script incrementally without running the entire file.\nSource – The Source button runs the entire R script from start to finish in the current R session. This executes all lines of code in order, but only prints output that your code explicitly generates. It’s ideal for running complete scripts or reproducing analyses.\nSource with Echo (this is an option found in the ↓ button next to ‘Source’) – This option also runs the entire script, but in addition, it prints each command to the console as it runs. This is helpful for debugging or reviewing what the script is doing, because you can see both the commands and their results in real time.\nEXPERIMENT: Try clicking Source and see what’s outputted in the ‘Console’ window (bottom left quarter of RStudio). Also try clicking on the other two options to see how they all differ.\n\n\nRStudio Close an R Script file\nClosing an R script file in RStudio is, thankfully, very easy!\nACTIVITY: Click the x button on the tab in RStudio where the name of your R file is…\n\n\n\nRStudio Open an R script file\nACTIVITY: Follow the steps below to open your saved R script file:\n\nClick on File → Open File… which will bring up the Open File window.\nNavigate to where your R file is saved (i.e. find the correct directory)\nSelect it and click’Open’\n\n\n\n\nSection summary\nYou should now be able to open, save and close an R script file in RStudio, well done!\nIn the next section, you’ll start creating a script that is more relevant to the degree that you’re studying…",
    "crumbs": [
      "Home",
      "Workshop 4",
      "Script 0: Hello, World!"
    ]
  },
  {
    "objectID": "Workshop4_Rscript2.html",
    "href": "Workshop4_Rscript2.html",
    "title": "The ifelse statement",
    "section": "",
    "text": "In this section, you’ll write your own R script (with a bit of help ;-)) to calculate how much stock solution is needed for multiple dilutions. You will also learn how to use the ifelse() function to flag dilutions automatically that use a high proportion of your stock. This combines practical chemistry calculations with ‘vectorized’ logical checks, showing how R can help you make lab planning faster and safer.\n\nWhat is the ifelse statement?\nThe ifelse() function is like a supercharged version of the if/else statements you learned earlier. Instead of checking a single condition, it can evaluate a whole vector of values at once and return a result for each one. This makes it perfect for tasks like our dilution script, where you want to check multiple samples or volumes simultaneously and get a quick, clear outcome for each.\n\n\n\n\n\n\nNote\n\n\n\nRemember: In R, a vector is a sequence of values of the same type (numbers, text, or logical) stored together as a single object.\n\n\n\nThe structure of an ifelse statement in R\nAn ifelse() statement has three parts:\n\nthe condition to check,\nthe value to return if the condition is true, and\nthe value to return if the condition is false.\n\nThe general structure looks like:\nifelse(condition, value_if_true, value_if_false)\nFor example, the code below enables you to flag whether a stock volume is safe to use.\nACTIVITY: Run the code below:\n\n\n\n\n\n\n\n\nWhen you have multiple values, ifelse() can check each one at the same time. This is called vectorized operation. For example, suppose we have three dilutions and want to flag which ones use too much stock…\nACTIVITY: Run the code below, look at the output and try to understand why the each of the results has been outputted:\n\n\n\n\n\n\n\n\nThe sep argument in the cat() function tells R what to put between the items you are printing. By default, cat() just prints everything together with a space.\nIf you use sep = \"\\n\", R prints each item on a new line.\nYou can also use other characters, like “,” to separate items with a comma and space.\n\n\n\nRStudio A simple dilution calculator\nIn this section, you will write an R script file.\nThe goal is to calculate how much stock solution you need to prepare one dilution, using the familiar formula:\n\\[C_1 V_1 = C_2 V_2\\]\nThis is one of the most important calculations you will ever do in the lab, so it’s the perfect place to start writing real code.\nYour script needs to be able to:\n\nStore values for the stock concentration (C₁), final concentration (C₂), and final volume (V₂)\n\nUse the dilution equation to calculate the volume of stock needed (V₁)\n\nPrint a clear, readable message telling you the result\nInstead of copying a finished script, you’ll build it piece by piece… the way a real coder would.\n\nACTIVITY: Do step 1:\nStep 1:: 1. Open RStudio\n2. Go to File → New File → R Script\n3. A blank script window will open\n4. Save the file immediately as: simple_dilution.R\nYou’ll now add the script code yourself!\nStep 2: At this point, it’s always good to describe what you are hoping your code will do.\nACTIVITY: Type this (or something along these lines) at the top of your blank script:\n# Simple Dilution Calculator\n# Calculates V1 using C1 * V1 = C2 * V2\nThis makes your script readable and helps you get used to how R scripts begin.\nStep 3: Create your variables… your script needs three pieces of information:\n\nstock concentration (C₁)\nfinal concentration (C₂)\nfinal volume (V₂)\n\nACTIVITY: Add these lines to your script (typing them yourself):\nstock_conc &lt;- \nfinal_conc &lt;- \nfinal_vol  &lt;- \nACTIVITY: Now fill in the numbers… for example, try C₁ = 5 mg/mL, C₂ = 2 mg/mL, V₂ = 50 mL. But feel free to choose any realistic values you want!\nStep 4: You now need to add the dilution calculation.\nACTIVITY: type the exact line below under your variables:\nV_stock_needed &lt;- (final_conc * final_vol) / stock_conc\nThis uses your numbers and the formula to calculate V₁.\n*Step 5: You now need a command that prints your result!\nACTIVITY: At the end of your script, type:\ncat(\"You need\", round(V_stock_needed, 2), \"mL of stock solution.\\n\")\n\n\n\n\n\n\nNote\n\n\n\nThe round() function in R is used to make numbers easier to read by shortening them to a set number of decimal places. It takes a number and rounds it to the number of decimal places you choose. Here, the values are\n\n\nStep 5: Now let’s run your script!\nACTIVITY: Click Source (top right of the script pane), then look in the Console for your result.\nEXPERIMENT: Try changing your values and running again.\nThis is how chemists use code to check dilutions quickly and accurately.\n\nWow! You built your first R script!!\nWell done. You didn’t just copy code… you constructed a real calculation script exactly the way working scientists do.\nNext, we’ll extend this idea to more a complex script that handles multiple dilutions at once.\n\n\n\nA multiple dilution calculator in R\nThe code below allows you to undertake complex diltion calculations with multiple dilutions at once.\n# -----------------------------------------------------\n# Multiple Dilution Calculator\n# -----------------------------------------------------\n# This script calculates the volume of stock solution (V1)\n# needed for several dilutions using C1 * V1 = C2 * V2.\n# It also checks whether each dilution uses more than 80%\n# of the available stock and labels it as \"High usage\" or \"Safe\".\n# -----------------------------------------------------\n\n\n# --- 1. Stock information ---\n\n# Stock concentration (C1, mg/mL)\nstock_conc &lt;- 5\n\n# Total volume of stock available (mL)\nstock_available &lt;- 80\n\n\n# --- 2. Final solution requirements (vectors!) ---\n\n# Desired final concentrations (C2, mg/mL)\nfinal_conc &lt;- c(2, 1.5, 3)\n\n# Final volumes to prepare (V2, mL)\nfinal_vols &lt;- c(50, 100, 75)\n\n\n# --- 3. Calculate volumes of stock needed (V1) ---\n\nV_stock_needed &lt;- (final_conc * final_vols) / stock_conc\n\n\n# --- 4. Check % stock used by each dilution ---\n\nstock_fraction &lt;- V_stock_needed / stock_available\n\nusage_label &lt;- ifelse(stock_fraction &gt; 0.8,\n                      \"High usage\",\n                      \"Safe\")\n\n\n# --- 5. Print results clearly ---\n\ncat(\"Dilution results:\\n\")\ncat(\"-----------------------------\\n\\n\")\n\nfor (i in seq_along(V_stock_needed)) {\n  cat(\"Sample\", i, \":\\n\")\n  cat(\"  C2 =\", final_conc[i], \"mg/mL\\n\")\n  cat(\"  V2 =\", final_vols[i], \"mL\\n\")\n  cat(\"  Stock needed =\", round(V_stock_needed[i], 2), \"mL\\n\")\n  cat(\"  Usage =\", usage_label[i], \"\\n\\n\")\n}\nACTIVITY: Copy the code above, create a new script file (name it yourself!), paste and try running (remember: use Source).\nEXPERIMENT: Try editing the stock concentration (stock_conc), the stock amount that’s available (stock_available), the final concentrations (final_conc) and volumes (final_vols) - you should be able to see how much stock each sample uses, which ones use a lot of stock, how changing concentrations alters V₁ and, finally, how vectors let R calculate many things at once.\n\n\nSection summary\nIn this section, you learned how R can quickly handle several dilution calculations at once. Instead of calculating each dilution separately, you stored all your final concentrations and volumes in vectors, allowing R to process each sample automatically. You also used an ifelse() statement to check whether a dilution used more than 80% of the available stock — a simple but powerful example of how computers make decisions based on conditions.\nYour script currently checks each dilution individually, which is perfect for building confidence with vector calculations and conditional logic. In real laboratory planning you’d also want to check whether the total stock needed for all dilutions combined exceeds what is available… something we can add later as your scripts become more sophisticated. For now, you have built a practical, flexible tool that introduces the essential logic behind automated dilution calculations.\nBy writing and running your own script, you now have a reusable tool: change the input values and R instantly recalculates everything for you. This is exactly how scientists use code to plan solutions efficiently and avoid costly lab mistakes. You’ve combined chemistry, logic, and scripting to produce something genuinely useful, well done!",
    "crumbs": [
      "Home",
      "Workshop 4",
      "The `ifelse` statement"
    ]
  },
  {
    "objectID": "Workshop5_introduction.html",
    "href": "Workshop5_introduction.html",
    "title": "Introduction to Workshop 5",
    "section": "",
    "text": "In this session, we’ll build on the R scripting and plotting skills you’ve developed so far and apply them to analysing real chemical and pharmaceutical science data. You’ll work with simple but realistic datasets (such as calibration data) to explore how measured variables relate to one another, using R as a tool to support scientific interpretation rather than just number-crunching.\n\n\nBy the end of this workshop, you’ll be able to visualise relationships between variables using scatter plots, quantify how strongly those variables are related using correlation, and fit simple linear regression models to experimental data. You’ll also learn how to interpret these results in a meaningful scientific context, understand what model parameters represent physically, and recognise the limitations of correlation and linear models when applied to real experimental measurements.\nAs per Workshop 4, I’ll be using two badges: WebR and RStudio to denote whether the text (and tasks for you to work through) relates to the browser (this is WebR) or RStudio.",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Introduction to Workshop 5"
    ]
  },
  {
    "objectID": "Workshop5_introduction.html#welcome-to-workshop-5-correlation-linear-regression",
    "href": "Workshop5_introduction.html#welcome-to-workshop-5-correlation-linear-regression",
    "title": "Introduction to Workshop 5",
    "section": "",
    "text": "In this session, we’ll build on the R scripting and plotting skills you’ve developed so far and apply them to analysing real chemical and pharmaceutical science data. You’ll work with simple but realistic datasets (such as calibration data) to explore how measured variables relate to one another, using R as a tool to support scientific interpretation rather than just number-crunching.\n\n\nBy the end of this workshop, you’ll be able to visualise relationships between variables using scatter plots, quantify how strongly those variables are related using correlation, and fit simple linear regression models to experimental data. You’ll also learn how to interpret these results in a meaningful scientific context, understand what model parameters represent physically, and recognise the limitations of correlation and linear models when applied to real experimental measurements.\nAs per Workshop 4, I’ll be using two badges: WebR and RStudio to denote whether the text (and tasks for you to work through) relates to the browser (this is WebR) or RStudio.",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Introduction to Workshop 5"
    ]
  },
  {
    "objectID": "Workshop5_exploring-data.html",
    "href": "Workshop5_exploring-data.html",
    "title": "Exploring Relationships in Experimental Data",
    "section": "",
    "text": "Important\n\n\n\nIn chemistry and pharmaceutical science, data analysis should always begin by looking at the data. Before calculating statistics or fitting models, we first visualise relationships to assess whether further analysis is appropriate.\n\n\nThis first section broadly refreshes everything that we covered in workshops 1-4. If an instruction doesn’t seem familiar, please revisit the earlier workshops.\n\nWebR Creating a small experimental dataset\nWe’ll start by creating a small dataset directly in R. This represents the type of data that you might collect during a UV–Vis calibration experiment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nACTIVITY: In the box below, type in the command needed to print this data out.\n\n\n\n\n\n\nNote\n\n\n\nRemember, in these boxes, if you’re not sure, you can click on ‘Hint’ to get a hint (normally, very strong!) about what to enter :-).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nIn order to print the data, you simply need to type the name of the data (in this case, it’s called ‘calibration’).\n\n\n\n\n\n\n\ncalibration\ncalibration\n\n\n\n\n\n\nTake a moment to check that you understand what each column represents and what the units are.\n\n\nVisualising the relationship\nThe next step is to visualise the relationship between the two variables. A scatter plot is the most appropriate choice when comparing two continuous measurements. If you’re not sure how to do this, please revisit Workshop 3, when we went through a whole lot of different types of plot visualisations using ggplot2.\nACTIVITY: Try running the command below to plot your data:\n\n\n\n\n\n\n\n\nLook carefully at the plot. Ask yourself whether a straight-line relationship seems reasonable!\nAs a refresher, let’s try improving this plot by adding labels, a title and a clean theme\n\n\nImproving the plot\nLet’s start by running the below…:\n\n\n\n\n\n\n\n\nWhat’s changed between this graph and the previous one that you generated?\nEXPERIMENT: Try modifying the plot to:\n\nchange the point size or colour\ntry a different theme (e.g. theme_classic, theme_dark, theme_void etc.)\n\n\n\nRStudio Saving your work in a script\nLet’s now swap over to RStudio. Remember, as we’re using ggplot to create some graphs, we have to ensure that relevant packages are installed and then loaded.\nACTIVITY: You therefore need to run the commands:\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\nNow open a new R script file, copy the text below and paste into the file:\ncalibration &lt;- data.frame(\n  concentration_mM = c(0.00, 0.05, 0.10, 0.20, 0.40),\n  absorbance = c(0.02, 0.14, 0.29, 0.59, 1.18)\n  )\nggplot(calibration, aes(x = concentration_mM, y = absorbance)) +\ngeom_point(size = 3, colour = \"blue\") +\nlabs(\nx = \"Concentration (mM)\",\ny = \"Absorbance\",\ntitle = \"UV–Vis Calibration Data\"\n) +\ntheme_minimal()\nThen save (user’s choice for the name of the file :-)). You can now use this in future if you wish to plot anything!\nThe next section will look at starting to quantify relationships using correlation…",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Exploring Relationships in Experimental Data"
    ]
  },
  {
    "objectID": "Workshop5_correlating-data.html",
    "href": "Workshop5_correlating-data.html",
    "title": "Quantifying Relationships with Correlation",
    "section": "",
    "text": "After visualising your data in Section 1, the next step is to quantify how strongly two variables are related. In chemistry and pharmaceutical science, this helps us understand whether one measurement reliably changes with another.\n\nWebR Calculating Pearson correlation\nThe most common correlation measure is Pearson correlation, which quantifies linear relationships. It ranges from -1 (perfect negative) to +1 (perfect positive), with 0 meaning no linear relationship.\nIn R, the cor() function calculates the correlation for us. We’ll use the same calibration data as in the previous section!\n\n\n\n\n\n\n\n\n\n\n\n\nWhen you call the function cor(x,y), it looks at two numeric vectors (here: our concentration and absorbance) and calculates a single number between -1 and 1.\nHow to interpret it:\n\n\n\n\n\n\n\nValue\nMeaning\n\n\n\n\n+1\nPerfect positive linear relationship (as x increases, y increases proportionally)\n\n\n0\nNo linear relationship\n\n\n-1\nPerfect negative linear relationship (as x increases, y decreases proportionally)\n\n\n\n\nThe closer the number is to 1 or -1, the stronger the linear relationship.\nIf the number is near 0, there is little or no linear connection.\n\n\n\n\n\n\n\nImportant\n\n\n\ncor is effectively R (from the more well known R2 term)… so if you want R2, simply square the cor value!\n\n\nACTIVITY: What does this mean about our calibration data?\n\n\nWebR Exploring Spearman correlation\nSometimes the relationship is monotonic but not perfectly linear. Spearman correlation uses ranks instead of actual values and is less sensitive to outliers.\n\n\n\n\n\n\nNote\n\n\n\nThe term monotonic means that the variables tend to more in the same direction but not necessarily at a constant rate - so, for example, you might have a section in the graph that increases slowly, then another section that increases faster etc. Notably, there won’t be any sections that decrease.\n\n\nACTIVITY: The command below allows you to run a Spearman correlation. Try it and see what you get out!!\n\n\n\n\n\n\n\n\nSo… Spearman correlation measures whether two variables change together in a consistent way, even if the relationship is not a straight line.\nInstead of using the raw values, Spearman correlation ranks the data (from smallest to largest), then checks whether the ranks increase or decrease together.\nJust like Pearson correlation, Spearman correlation gives a number between –1 and +1:\n\n+1 → as one variable increases, the other always increases\n–1 → as one variable increases, the other always decreases\n0 → no consistent relationship\n\nThe closer the value is to ±1, the stronger and more consistent the relationship.\nAll this means that Spearman correlation works better for curved trends, but less sensitive to outliers.\n\n\n\n\n\n\nImportant\n\n\n\nA strong correlation does NOT mean causation. In our case, a high correlation is expected because absorbance increases with concentration, but correlation alone does not give a predictive model.\n\n\n\n\nRStudio Consolidating your correlation analysis\nNow let’s move your work into your script in RStudio…\nACTIVITY:\n\nAdd to your existing script from the previous section.\nInclude both the Pearson and Spearman correlations.\nAdd brief comments interpreting the results scientifically. Remember: you use a # to add comments that are not read by R.\n\n\n\n\n\n\n\nImportant\n\n\n\nCorrelation is a numerical summary, not a predictive model. We will learn how to create models in the next section.",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Quantifying Relationships with Correlation"
    ]
  },
  {
    "objectID": "Workshop5_linear-regression.html",
    "href": "Workshop5_linear-regression.html",
    "title": "Modelling Relationships with Linear Regression",
    "section": "",
    "text": "Correlation tells us how strongly two variables are related, but it does not give us an equation. In this section, we will use linear regression to build a simple mathematical model that describes the relationship between concentration and absorbance.\n\nWebR From correlation to a model\nA linear regression model describes the relationship between two variables using a straight-line equation:\n\\[ y = mx + c \\]\nIn our case:\n\n𝑥 is concentration\n𝑦 is absorbance\n\nR can fit this model directly from the data.\nACTIVITY: Let’s fit a linear regression model to our calibration data from earlier:\n\n\n\n\n\n\n\n\nTake a moment to look at the output. There are a few key pieces of information:\n1. Coefficients This section gives the numbers for the straight-line equation: \\[ y = mx + c \\] You will see two rows:\n\n(Intercept) This is the value of 𝑐. It represents the absorbance when the concentration is zero (background or baseline signal).\nconcentration_mM This is the slope 𝑚. It tells you how much the absorbance changes for each unit increase in concentration.\n\n2. Standard error This tells you how far the data points typically are from the fitted line.\n\nA smaller value means the data lie closer to the line\nA larger value means there is more scatter around the model\n\n3. Multiple R squared This tells you how well the straight line explains the data. This value is closely related to the correlation you calculated earlier.Think of this as a measure of experimental noise.\n\nValues range from 0 to 1.\nA value close to 1 means the linear model explains most of the variation in absorbance.\nFor a good calibration curve, R2 is usually high.\n\n\n\nVisualising the fitted model\nACTIVITY: It’s good practice to plot the regression line on top of the data. This allows us to check visually how well the model fits.\n\n\n\n\n\n\n\n\nEXPERIMENT: Compare this plot to the scatter plot from the earlier section. The line should follow the trend in the data closely.\n\n\nWhat does the model tell us?\nThe regression model gives us more than a visual trend:\n\nit provides an equation\nit allows prediction\nit can be used to evaluate how suitable a linear model is.\n\nHowever, a good numerical fit does not automatically mean the model is chemically valid.\n\n\nRStudio Saving and commenting your model\nOnce you’ve checked that the model works in WebR, you should save it in your script.\nACTIVITY: In RStudio:\n\nAdd the lm() model to your script\nInclude the regression plot\nWrite short comments explaining:\n\n\nwhat the slope represents physically,\nwhat a high R2 means in this context.\n\n\n\n\n\n\n\nImportant\n\n\n\nA regression model is a scientific tool. Always interpret its parameters in terms of the experiment.\n\n\nOne more section to go…",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Modelling Relationships with Linear Regression"
    ]
  },
  {
    "objectID": "Workshop5_limits.html",
    "href": "Workshop5_limits.html",
    "title": "Using the Model and Knowing Its Limits",
    "section": "",
    "text": "A linear regression model is most useful when it can be applied to real experimental problems. In this final section, we will briefly use the model for prediction and reflect on when a linear model should and should not be trusted.\n\nWebR Using the model for prediction\nOnce a model has been fitted, it can be used to estimate values that were not directly measured. Let’s try getting the model to predict an absorbance value for a concentration of 0.15 mM:\n\n\n\n\n\n\n\n\nThis is how calibration curves are typically used in practice: the model allows us to estimate unknown values from measured data.\n\nThinking about limitations\nEven when a model fits the data well, it is important to think critically about its validity.\nA linear model may not be appropriate if:\n\nthe relationship is not truly linear,\nresiduals show a clear pattern,\nmeasurements approach instrumental limits, or\nexperimental uncertainty increases at high values.\n\n\n\nFinal takeaway\nLinear regression is a powerful tool, but it should always be used alongside:\n\nclear visualisation,\nchemical understanding, and\nscientific judgement.\n\n\n\n\n\n\n\nImportant\n\n\n\nA good model is not just statistically sound — it must also make sense chemically.",
    "crumbs": [
      "Home",
      "Workshop 5",
      "Using the Model and Knowing Its Limits"
    ]
  }
]