[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "mean(c(1, 2, 3))\n\n[1] 2"
  },
  {
    "objectID": "intro.html#quarto",
    "href": "intro.html#quarto",
    "title": "Introduction",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "intro.html#running-code",
    "href": "intro.html#running-code",
    "title": "Introduction",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n\n\n\n\n\n\nYou can add options to executable code like this\n\n\n\n\n\n\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CH4004-R.github.io",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Workshop2.html#welcome-to-workshop-2-cleaning-and-wrangling-your-chemistry-data",
    "href": "Workshop2.html#welcome-to-workshop-2-cleaning-and-wrangling-your-chemistry-data",
    "title": "Workshop 2",
    "section": "Welcome to Workshop 2: Cleaning and Wrangling Your Chemistry Data",
    "text": "Welcome to Workshop 2: Cleaning and Wrangling Your Chemistry Data\nIn this workshop, you will learn how to:\n\nLoad a chemistry dataset into R\nInspect the data to identify common issues\nPrepare for cleaning and wrangling tasks\n\nWe will be working with two datasets:\n\nThe ESOL dataset, which contains aqueous solubility data for chemical compounds. This dataset has some intentional data issues for you to spot and fix.\nThe Lipophilicity dataset, which contains experimental logD values for small molecules, where the term lipophilicity represents a measure of how well a substance dissolves in fats, oils and lipids vs water!\n\n\nHow to use Code Chunks in this Worksheet?\nIn this tutorial, you’ll see two types of code chunks:\n\nRun Code chunks: These are for trying things out — there’s no “Submit Answer” button. Just write code and click Run Code to see what happens!\nSubmit Answer chunks: These ask you to complete a task. Once you’re happy with your answer (you can test it using Run Code), click Submit Answer to check your work… you’ll get feedback right away.\n\nSome exercises also come with Hint buttons to help you if you get stuck. Give it a try, there’s no penalty for exploring or making mistakes!\n\n\nExample 1: “Run Code” type 1 Chunk\nThis is a Run Code chunk: there’s nothing to submit, you’re just playing with code!\nTry running the code below to make R say hello:\n\n\n\n\n\n\n\n\n\n\n\nExample 2: “Run Code” Chunk type 2 (for graded feedback)\nThis is also a Run Code chunk. But… this time, after you’ve typed your answer and clicked Run Code, you’ll get graded feedback that will tell you if you’re correct and may even give you a hint about how to improve your answer!\nTalking of hints… you’ll see that, in this example, that there is also a button called Show Hint. Try clicking it and see what happens!\nIn this example, we’ll use nchar() to count the number of letters in the word \"banana\" and assign it to a variable called banana_length. Simply fill in the blank!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nRemember to keep the name of the word to be counted in inverted commas ” “.\n\n\n\n\n\n\n\nbanana_length &lt;- nchar(\"banana\")\nbanana_length &lt;- nchar(\"banana\")\n\n\n\n\n\n\n\n\nData Source Acknowledgement\nThe ESOL and Lipophilicity datasets used in this workshop are from MoleculeNet,\na benchmarking platform for molecular machine learning datasets.\nPlease refer to Wu et al., MoleculeNet: a benchmark for molecular machine learning, Chemical Science, 2018, 9, 513-530 for details.\nWe thank the authors and contributors for making these datasets publicly available."
  },
  {
    "objectID": "Workshop2.html#understanding-r-packages",
    "href": "Workshop2.html#understanding-r-packages",
    "title": "Workshop 2",
    "section": "Understanding R packages",
    "text": "Understanding R packages\nIf you remember from last week, packages in R are like plug-ins or apps for R. They add extra tools and features that don’t come built-in, so you can do more things easily, such as reading data files or cleaning your data.\nIn this case, as we’ll be importing and manipulating datasets today, we’ll use the readr package to import .csv files and dplyr for data manipulation.\n\nHow package installation works\nWhen working on your own computer and R, you would install packages using the install.packages() command. For example:\ninstall.packages(\"readr\")\ninstall.packages(\"dplyr\")\nHowever, for the sakes of this tutorial, these have already been installed automatically for you. In R Studio, you can find out which packages have been installed by looking at the ‘Packages’ tab in the bottom right pane to spot them!\nImportant notes about installing packages:\nPackage names must be in quotation marks: install.packages(\"dplyr\"). Without quotes, as shown in the example here, you’ll get an error: install.packages(dplyr)\nYou only need to install a package once on your computer (assuming that this is not using the KU environment, which wipes this!). The setup script already checked for you and only installed packages you didn’t already have.\n\n\nExercise: Loading packages\nAfter packages are installed, you need to load them to use their functions. This is done with the library() function. Slightly differently from install.packages, you don’t have to have inverted commas around the name though (it doesn’t matter whether you have them or not). For example, if you wanted to load the ‘beepr’ package (having installed it first!), you’d type:\nlibrary(bleepr)\nIn case, by the way, you’re wondering what the bleepr package is, it’s as the name suggests… a package that enables you to get an audible alert whenever your code finishes.\nAnyway, back to the task at hand! Think of the difference between using install.packages and library like downloading an app from an app Store vs opening an app. You only need to download an app once on your device (or in your R environment). However, even if the app is installed, you can’t use it until you open it. And… every time you restart your computer or your phone (or R session), you’ll need to open the app again.\nTry loading both readr and dplyr in the box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nUse the library() function to load packages! Package names do NOT need quotes in library. For the package readr this would look like:\nlibrary(readr)\nNow you do the same for dplyr!\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 2\n\n\n\n\n\nUse the library() function to load packages. Remember, package names do NOT need quotes in library().\nlibrary(readr)\nlibrary(dplyr)\n\n\n\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(dplyr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: Again, just to reiterate, unlike installation (i.e. using install.packages), you need to load packages with library() every time you start a new R session!"
  },
  {
    "objectID": "Workshop2.html#why-cleaning-your-data-matters-in-chemistry",
    "href": "Workshop2.html#why-cleaning-your-data-matters-in-chemistry",
    "title": "Workshop 2",
    "section": "Why Cleaning Your Data Matters in Chemistry",
    "text": "Why Cleaning Your Data Matters in Chemistry\nIn pharmaceutical and chemical research, your data is only as good as its quality.\nWhether you’re working with:\n\nExperimental data (e.g. solubility measurements from the lab), or\n\nLiterature-mined data (e.g. scraped or compiled from journal articles or public databases),\n\n…there are often errors, inconsistencies, or missing values that need fixing before any meaningful analysis.\n\nCommon data problems in chemistry:\n\nMissing or incomplete values (e.g. no logS reported for some compounds)\n\nUnits or scales that don’t match (e.g. logP vs. logD, or µg/mL vs. mol/L)\n\nInconsistent naming of chemical compounds\n\nDuplicate entries in literature-mined datasets\n\nImplausible values (e.g. negative molecular weights!)\n\n\nWhy it matters:\nIf we skip the cleaning step, we risk drawing wrong conclusions — or feeding errors into models or visualisations. It’s like trying to bake a cake with the wrong ingredients."
  },
  {
    "objectID": "Workshop2.html#importing-the-esol-dataset",
    "href": "Workshop2.html#importing-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Importing the ESOL Dataset",
    "text": "Importing the ESOL Dataset\nNow let’s load a sample dataset: ESOL, a solubility dataset containing chemical compounds with their predicted aqueous solubility (logS), molecular weight (MolWt), and other properties.\n\nWe’ve introduced a few intentional issues to simulate what real chemical datasets often look like!\n\nYou can access the file esol_messy.csv from the data folder associated with this tutorial.\n\n\nExercise: Import the ESOL dataset\nYou’re going to import the file esol_messy.csv into R using read_csv() from the readr package.\n\nImportant reminder:\nWhen you use read_csv(), it reads the data — but it doesn’t automatically store it anywhere.\nYou need to assign the result to a data frame (just like we did last week) using the &lt;- operator.\n\nFor this exercise, please assign your data to an object called esol_data. The file itself is called esol_messy.csv and it’s in a folder called data. You will therefore have to group these two together as: data/esol_messy.csv.\nOkay… your go! Please have a go at importing your data using read_csv():\n\n\n\n\n\n\n\n\nHopefully that’s worked!! Don’t worry if your code didn’t quite work though… I’ve made sure the dataset is available behind the scenes so you can still follow along with the next steps. But… just in case you had any issues, and if you want to keep on, feel free to go back and try again!\nTip: You can use the print() command with the name of your variable (here: esol_data) e.g. print(VARIABLE) to display the entire dataset (or as much of it as fits in your window). This can help you get a quick overview of the data contents. Why don’t you try that in the box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nUse the print() function with the name of the function (here: esol_data)\nprint(esol_data)\n\n\n\n\n\n\n\nprint(esol_data)\nprint(esol_data)\n\n\n\n\n\n\nTake particular note of the names of the columns (you’ll need this later).\nFYI, you can add a couple of options to the print command: n = and width = e.g. print(VARIABLE, n = 25, width = Inf) to change the number of columns and rows shown"
  },
  {
    "objectID": "Workshop2.html#exploring-the-esol-dataset",
    "href": "Workshop2.html#exploring-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Exploring the ESOL Dataset",
    "text": "Exploring the ESOL Dataset\nNow that you’ve imported the ESOL dataset, let’s take a look at what we’re dealing with.\nThis data was collected from a combination of experimental and literature-mined sources. While useful, it’s also a bit… messy.\nLet’s inspect it to see what needs cleaning!\nThree useful functions to help you explore any data frame are:\n\nhead(data) – shows you the first few rows of your data. Great for a quick peek!\nstr(data) – shows you the structure of the dataset: column names, data types, and examples.\nsummary(data) – gives you summary statistics for each column: min, max, median, and so on.\n\n\nTry this in the code box below:\nUse the following functions to explore your dataset. The # symbol can be useful for you here… in code, it means ‘comment’ and tells R not to read either itself or anything after it on the same time. When coding, it’s important to comment throughout so that both you and anyone else can understand your code.\nSo… try using the # symbol to block out any two of the functions at any one time, then select ‘run code’ to see what the other function does - and then repeat the loop for the other two functions.\n\n\n\n\n\n\n\n\n\n\nWhat should you be looking for?\nAs you explore the data, keep an eye out for:\n\nMissing values — are there any NAs?\nWeird formatting — for example, compound names in ALL CAPS or with trailing spaces\nOutliers — very large or small values that don’t seem realistic\nDuplicates — are there repeated compounds?\n\nThese are all common issues in real-world datasets, and spotting them is the first step toward fixing them!"
  },
  {
    "objectID": "Workshop2.html#cleaning-the-esol-dataset",
    "href": "Workshop2.html#cleaning-the-esol-dataset",
    "title": "Workshop 2",
    "section": "Cleaning the ESOL Dataset",
    "text": "Cleaning the ESOL Dataset\nNow that you’ve had a chance to explore the dataset, let’s start cleaning it!\nWe’ll do this step by step using dplyr functions (you should have loaded this into the memory earlier using library(dplyr)). Your job is to fill in the blanks.\n\n\n\n\n\n\nNote\n\n\n\nTip: Use filter() to remove rows, mutate() to create or modify columns, and distinct() to remove duplicates.\n\n\nTry the code below. Fill in the blanks with the appropriate column heading name (you’ll need to remove the “____” bits first (just remember this is important that if your heading has spaces in, you’ll need to put the whole heading name between backticks i.e. `. Thebacktick ` button is often found just above the ‘tab’ button)!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nRemember, the names of the headings are: The compound names: Compound ID The logS values: ESOL predicted log solubility in mols per litre\n\n\n\n\n\n\n\n\n# Start with the original esol_data\nclean_esol &lt;- esol_data %&gt;%\n  # 1. Remove rows where logS is missing\n  filter(!is.na(`ESOL predicted log solubility in mols per litre`)) %&gt;%\n  # 2. Standardise the compound names\n  mutate(compound = tolower(trimws(`Compound ID`))) %&gt;%\n  # 3. Remove duplicate rows\n  distinct()\n\n# Start with the original esol_data\nclean_esol &lt;- esol_data %&gt;%\n  # 1. Remove rows where logS is missing\n  filter(!is.na(`ESOL predicted log solubility in mols per litre`)) %&gt;%\n  # 2. Standardise the compound names\n  mutate(compound = tolower(trimws(`Compound ID`))) %&gt;%\n  # 3. Remove duplicate rows\n  distinct()\n\n\n\n\n\n\n\nUnderstanding Each Cleaning Step\nLet’s take a moment to understand exactly what each line of the cleaning pipeline is doing…\nclean_esol &lt;- esol_data %&gt;%\nWe’re building a data cleaning pipeline using the pipe operator (%&gt;%). This means each line takes the result from the previous step and passes it forward to the next one.\nLet’s break it down step-by-step:\n\n(a) filter(!is.na(\"  \"))\nfilter(!is.na(`ESOL predicted log solubility in mols per litre`))\n\nfilter() is used to keep only certain rows of the data.\nis.na(ESOL predicted log solubility in mols per litre) checks for missing values (NAs) in the “ESOL predicted log solubility in mols per litre” column.\n!is.na(ESOL predicted log solubility in mols per litre) means “not missing”, so this line keeps only rows where there is a value for logS.\n\n\n\n(b) mutate(compound = tolower(trimws(\"   \")))\nmutate(compound = tolower(trimws(`Compound ID`)))\n\nmutate() is used to modify or create a new column.\nInside it, we’re creating a new compound column.\ntrimws() removes leading and trailing whitespace from the compound names.\ntolower() converts all characters to lowercase.\n\nTogether, this helps standardise the formatting of compound names (e.g. fixing ” ACETAMINOPHEN ” to “acetaminophen”).\n\n\n(c) distinct()\ndistinct()\n\nThe command distinct() removes duplicate rows from the data frame.\nSometimes in real datasets, the same compound appears more than once — this helps clean that up.\nIf you want to remove duplicates only based on certain columns, you can do: distinct(compound, .keep_all = TRUE).\n\n\n\n\nFinal result\nThe cleaned dataset is now stored in a new object called clean_esol. This is what you’ll use going forward in your analysis — it’s more reliable and ready for real work!"
  },
  {
    "objectID": "Workshop2.html#comparing-the-messy-and-clean-esol-data",
    "href": "Workshop2.html#comparing-the-messy-and-clean-esol-data",
    "title": "Workshop 2",
    "section": "Comparing the Messy and Clean ESOL Data",
    "text": "Comparing the Messy and Clean ESOL Data\nNow that you’ve cleaned your dataset and created esol_clean, let’s compare it to the original messy version (esol_messy) to see what’s changed.\n\n\n\n\n\n\n\n\n\n1. Compare Dimensions\nUse nrow() and ncol() to check how many rows and columns each version (i.e. esol_data and clean_esol) has. Run the code below to see what happens…\n\n\n\n\n\n\n\n\n\n\n2. Compare Summaries\nUse summary() to compare key columns (like logS (i.e. “ESOL predicted log solubility in mols per litre”) or MolWt i.e. “Molecular Weight”). Try running the code below and then the column for another.\n\n\n\n\n\n\n\n\n\n\n3. Compare Unique Compounds\nLet’s see how many unique compounds are in each dataset. Remember, earlier you created a new column called ‘compound’ when you cleaned the ‘Compound ID’ column.\n\n\n\n\n\n\n\n\n\n\nSpot Formatting Fixes\nTry printing a few rows to visually inspect any fixes to formatting.\n\n\n\n\n\n\n\n\nYou should see that names in the cleaned data are now lowercase and free of trailing spaces.\n\n\nWhat Should You Notice?\n\nFewer rows? Good! You cleaned out invalid entries or duplicates.\nImproved summaries? Excellent — weird or missing values are likely gone.\nTidier names? Formatting is more consistent for analysis or merging.\n\nYou’re now ready to move on to combine this cleaned data with another!"
  },
  {
    "objectID": "Workshop2.html#combining-datasets-using-a-shared-column",
    "href": "Workshop2.html#combining-datasets-using-a-shared-column",
    "title": "Workshop 2",
    "section": "Combining Datasets Using a Shared Column",
    "text": "Combining Datasets Using a Shared Column\nNow that you’ve had practice cleaning the ESOL dataset, it’s time to bring in a second dataset Lipophilicity and learn how to combine datasets in R!\nIn real-world data science, it’s often helpful to combine different datasets to create a richer picture of your information. Here, we’ll match compounds between datasets using a common column: the SMILES string, which uniquely encodes the structure of each molecule.\n\nWhat is SMILES?\nSMILES stands for Simplified Molecular Input Line Entry System. It’s a compact way to represent a chemical structure using a string of text (e.g., \"CCO\" for ethanol).\nBoth the ESOL and Lipophilicity datasets contain a SMILES column (actually written in lowercase in the datasets), so even if the compounds are named differently elsewhere, we can match them using this column.\nThe Lipophilicity dataset has already been imported and cleaned, just to save you the trouble! This cleaned dataset is in a dataframe called: clean_lipo. Remember, your cleaned ESOL dataset is also in a dataframe called: clean_esol.\n\n\n\nJoining Two Datasets in R\nIn R, we use the dplyr::left_join() function to combine two data frames.\nHere’s what the syntax looks like:\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\nThis line says:\n\n“Take the clean ESOL data (clean_esol)…”\n“…and add matching rows from the clean Lipophilicity data (clean_lipo)…”\n“…based on the values in the SMILES column.”\n\nThe result is a new data frame (combined_data) that contains:\n\nAll rows from clean_esol\nAny matching columns from clean_lipo, added alongside\n\n\n\nWhy might some rows not match?\nRemember, not every molecule in the ESOL dataset will be found in the Lipophilicity dataset, and that’s okay! The left_join() function keeps all of the data from the left table (clean_esol), and only fills in values from clean_lipo where it finds matching SMILES codes.\nThis means we might see NAs in the Lipophilicity columns for compounds that don’t have a match… that’s completely normal!\nTry running it yourself in the blank box below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteHint 1\n\n\n\n\n\nLook above!\n\n\n\n\n\n\n\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\ncombined_data &lt;- left_join(clean_esol, clean_lipo, by = \"smiles\")\n\n\n\n\n\n\n\n\nExploring Your Joined Data: combined_data\nNow that you’ve created a new data frame called combined_data, let’s take a moment to explore it and see what you’re working with. Use the head(), str() and summary() commands that we covered earlier to do this in the box below:\n\n\n\n\n\n\n\n\n\n\nWell Done – You’ve Completed Workshop 2!\nYou’ve just worked through a full data cleaning and wrangling workflow using real chemistry datasets — that’s no small feat! Here’s a quick recap of what you accomplished:\n✅ You successfully imported messy chemical data using readr::read_csv()\n✅ You used dplyr and tidyr to clean and wrangle your data\n✅ You learned how to spot missing values, weird formatting, and duplicates\n✅ You created new variables and standardised your data\n✅ You joined two datasets using a common key (SMILES) to create a richer dataset\n✅ You explored your cleaned, combined dataset like a pro!\n\n\n\nWhat should you take away from this tutorial?\n\nCleaning data is a vital step in any data science project — messy data leads to misleading results.\nTools like filter(), mutate(), and select() give you full control over how your data is structured.\nCombining datasets can open the door to deeper analysis, comparisons, and insight — especially in fields like chemoinformatics.\n\n\n\nLicense: This tutorial is licensed under CC BY 4.0."
  }
]